{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment Mesh Analysis\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ecc4b83731736b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# external imports\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from shapely import (\n",
    "    from_geojson\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.371554Z",
     "start_time": "2024-03-13T22:32:04.086276Z"
    }
   },
   "id": "c8df69fe46cac602"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from src.utils.common_functions import (\n",
    "    json_file_to_dict,\n",
    "    get_list_files_in_path,\n",
    ")\n",
    "from src.utils.constants import (\n",
    "    EEE_COUNTRIES_FILEPATH,\n",
    "    REPLICATION_PACKAGE_DIR,\n",
    "    TRAFFIC_LOGS_IP_CLASSIFIED_FILEPATH,\n",
    "    ANYCAST_PII_TRAFFIC_LOGS_FILEPATH,\n",
    "    APKS_METADATA_FILEPATH,\n",
    "    RESULTS_MODES,\n",
    "    IT_ANNOTATION_FILEPATH,\n",
    "    TPLS_RESULTS_FILEPATH\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.376021Z",
     "start_time": "2024-03-13T22:32:04.372648Z"
    }
   },
   "id": "69d16f8da4f9071f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Constants\n",
    "EEE_countries_set = set([country[\"alpha-2\"] for country in json_file_to_dict(EEE_COUNTRIES_FILEPATH)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.379357Z",
     "start_time": "2024-03-13T22:32:04.376917Z"
    }
   },
   "id": "adb458e6157c0f69"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Analysis params\n",
    "DESTINATION_REPETITIONS_LIMIT = 1\n",
    "ANALYSIS_MODE=RESULTS_MODES[0]\n",
    "GENERATE_ROUTES_DATA=False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.382760Z",
     "start_time": "2024-03-13T22:32:04.380712Z"
    }
   },
   "id": "690c1391498feefb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Filepaths variables\n",
    "EXPERIMENT_RESULTS_FOLDER = f\"{REPLICATION_PACKAGE_DIR}/experiment_results_{ANALYSIS_MODE}\"\n",
    "ANALYSIS_FOLDER = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}\"\n",
    "\n",
    "ROUTES_RESULTS_FILENAME = f\"{ANALYSIS_FOLDER}/routes_results_{ANALYSIS_MODE}.csv\"\n",
    "ROUTES_FREQUENCY_FILENAME = f\"{ANALYSIS_FOLDER}/routes_frequency_{ANALYSIS_MODE}.csv\"\n",
    "\n",
    "ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Anycast_PII_Traffic_Logs_{ANALYSIS_MODE}.csv\"\n",
    "TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Traffic_logs_10K_ip_classified_{ANALYSIS_MODE}.csv\"\n",
    "ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_AGGREGATION_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Anycast_PII_Traffic_Logs_aggregation_{ANALYSIS_MODE}.csv\"\n",
    "TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_AGGREGATION_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Traffic_logs_10K_ip_classified_aggregation_{ANALYSIS_MODE}.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.388768Z",
     "start_time": "2024-03-13T22:32:04.383613Z"
    }
   },
   "id": "759dc69c48ceb4bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enrichment of data and generation of datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50b5569c9c01bcd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate a file with all the routes got as the result of the experiment execution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "829bbc8293d73e11"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def get_probe_location(probe_id: int, origin_list: []) -> (float, float):\n",
    "    for origin in origin_list:\n",
    "        if probe_id == origin[\"probe_id\"]:\n",
    "            location = from_geojson(origin[\"location\"])\n",
    "            return location.y, location.x\n",
    "        else:\n",
    "            continue\n",
    "    return 0, 0\n",
    "\n",
    "def get_result_country_route(hunter_result: dict) -> dict:\n",
    "    probe_id = hunter_result[\"origin_id\"]\n",
    "    result_country = hunter_result[\"location_result\"][\"country\"]\n",
    "    probe_country = hunter_result[\"origin_country_code\"]\n",
    "\n",
    "    return {\n",
    "        \"origin_id\": probe_id,\n",
    "        \"origin_country\": probe_country,\n",
    "        \"result_country\": result_country\n",
    "    }\n",
    "\n",
    "# Data generation function\n",
    "def generate_routes_raw():\n",
    "    routes_raw_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"target\", \"probe_id\", \"ips_previous_to_target\",\n",
    "            \"origin_country\", \"origin_latitude\", \"origin_longitude\", \n",
    "            \"result_country\", \"result_latitude\", \"result_longitude\",\n",
    "            \"result_filename\", \"outside_EEE\"\n",
    "        ]\n",
    "    )\n",
    "    for result_filename in get_list_files_in_path(EXPERIMENT_RESULTS_FOLDER):\n",
    "        print(result_filename)\n",
    "        result = json_file_to_dict(f\"{EXPERIMENT_RESULTS_FOLDER}/{result_filename}\")\n",
    "        target = result[\"target\"]\n",
    "        origin_list = result[\"measurements\"][\"origin\"]\n",
    "        for hunter_result in result[\"hunter_results\"]:\n",
    "            route = get_result_country_route(hunter_result)\n",
    "            probe_id = hunter_result[\"origin_id\"]\n",
    "            origin_country = route[\"origin_country\"]\n",
    "            origin_latitude, origin_longitude = get_probe_location(probe_id, origin_list)\n",
    "            \n",
    "            result_country = route[\"result_country\"]\n",
    "            if len(hunter_result[\"location_result\"][\"airports_intersection\"]) == 1:\n",
    "                result_location = from_geojson(hunter_result[\"location_result\"][\"airports_intersection\"][0][\"location\"])\n",
    "                result_latitude = result_location.y\n",
    "                result_longitude = result_location.x\n",
    "            else:\n",
    "                result_latitude = 0\n",
    "                result_longitude = 0\n",
    "                \n",
    "            outside_eee = (result_country not in EEE_countries_set) and (result_country != \"Indeterminate\")\n",
    "            \n",
    "            if result_country == \"Indeterminate\":\n",
    "                ips_previous_to_target = [\"Indeterminate\"]\n",
    "            else:\n",
    "                ips_previous_to_target = [\n",
    "                    ip[\"ip\"]\n",
    "                    for ip in hunter_result[\"ips_previous_to_target\"]\n",
    "                ]\n",
    "            \n",
    "            routes_raw_df = pd.concat(\n",
    "                [pd.DataFrame([[\n",
    "                    target, probe_id, str(ips_previous_to_target),\n",
    "                    origin_country, origin_latitude, origin_longitude, \n",
    "                    result_country, result_latitude, result_longitude,\n",
    "                    result_filename, outside_eee\n",
    "                ]], columns=routes_raw_df.columns), routes_raw_df], \n",
    "                ignore_index=True\n",
    "            )\n",
    "    # Sort and save\n",
    "    routes_raw_df.sort_values(by=[\"target\", \"origin_country\", \"result_country\"], inplace=True)\n",
    "    routes_raw_df.to_csv(ROUTES_RESULTS_FILENAME, sep=\",\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a4a5ff135ebc9cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregate and count routes repetitions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2905481c5a38b1ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data generation function\n",
    "def generate_routes_frequency_aggregation():\n",
    "    # Aggregate routes counting the repetitions\n",
    "    routes_frequency_df = pd.read_csv(ROUTES_RESULTS_FILENAME, sep=\",\")\n",
    "    routes_frequency_df = routes_frequency_df[[\"target\", \"origin_country\", \"result_country\"]]\n",
    "    routes_frequency_df = routes_frequency_df.value_counts(subset=['target', 'origin_country', 'result_country'])\n",
    "    routes_frequency_df.to_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\")\n",
    "    \n",
    "    # Include the info about outside the EEE\n",
    "    routes_frequency_df = pd.read_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\")\n",
    "    routes_frequency_df[\"outside_EEE\"] = False\n",
    "    \n",
    "    routes_frequency_df.loc[\n",
    "        (routes_frequency_df[\"result_country\"] != \"Indeterminate\") &\n",
    "        (~routes_frequency_df[\"result_country\"].isin(EEE_countries_set)),\n",
    "        [\"outside_EEE\"]\n",
    "    ] = True\n",
    "    routes_frequency_df.to_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.404975Z",
     "start_time": "2024-03-13T22:32:04.398604Z"
    }
   },
   "id": "1ef13530479b1cbb",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Introduce routes outside EEE and its count in the complete dataset WHAT DATASETS POPULATE????"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51ebb6a53d3489d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Dataset population function\n",
    "def populate_dataset_with_routes_results(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    routes_valid_df = pd.read_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\")\n",
    "    routes_valid_df = routes_valid_df.loc[\n",
    "        (routes_valid_df[\"outside_EEE\"] == True) & \n",
    "        (routes_valid_df[\"count\"] >= DESTINATION_REPETITIONS_LIMIT)\n",
    "    ]\n",
    "\n",
    "    # Charge default routes in the dataset to populate\n",
    "    dataframe[\"origins_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"destinations_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"frequency_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"outside_EEE\"] = False\n",
    "    \n",
    "    # For every IP get the list of origins, destinations and frequency and save it\n",
    "    for ip in routes_valid_df[\"target\"].unique().tolist():\n",
    "        ip_routes = routes_valid_df.loc[routes_valid_df[\"target\"] == ip]\n",
    "        origins_transfers_outside_eee = ip_routes[\"origin_country\"].values.tolist()\n",
    "        destinations_transfers_outside_eee = ip_routes[\"result_country\"].values.tolist()\n",
    "        frequency_transfers_outside_eee = ip_routes[\"count\"].values.tolist()\n",
    "\n",
    "        dataframe.loc[\n",
    "            (dataframe[\"ip_dest\"] == ip), \n",
    "            [\"origins_transfers_outside_EEE\", \n",
    "             \"destinations_transfers_outside_EEE\", \n",
    "             \"frequency_transfers_outside_EEE\",\n",
    "             \"outside_EEE\"]\n",
    "        ] = [str(origins_transfers_outside_eee),\n",
    "             str(destinations_transfers_outside_eee),\n",
    "             str(frequency_transfers_outside_eee),\n",
    "             True]\n",
    "    \n",
    "    return dataframe\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.413524Z",
     "start_time": "2024-03-13T22:32:04.406402Z"
    }
   },
   "id": "c5fdd5566a17a165",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with metadata info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4e872e6e4f5f347"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def populate_dataset_with_apks_metadata(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    apk_metadata_df = pd.read_csv(APKS_METADATA_FILEPATH, sep=\",\")\n",
    "    \n",
    "    return dataframe.merge(\n",
    "        apk_metadata_df,\n",
    "        on=[\"apk\", \"version\"],\n",
    "        how=\"left\"\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.417894Z",
     "start_time": "2024-03-13T22:32:04.414562Z"
    }
   },
   "id": "6b1c5cf65806854e",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with the info extrated from every policy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cce1d5fd8c0c621b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def populate_dataset_with_policy_extracted_info(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    it_annotation_results_df = pd.read_csv(IT_ANNOTATION_FILEPATH, sep=\",\")\n",
    "    \n",
    "    it_annotation_results_df.drop_duplicates([\"apk\", \"countries\"], inplace=True)\n",
    "    it_annotation_results_df.fillna(\n",
    "        value={\"countries\": \"[]\"},\n",
    "        inplace=True\n",
    "    )\n",
    "    it_annotation_results_df.rename(\n",
    "        columns={\n",
    "            \"transfer\": \"it_mentioned_by_policy\",\n",
    "            \"adequacy_decision\": \"adequacy_decision_by_policy\",\n",
    "            \"countries\": \"countries_mentioned_by_policy\"\n",
    "        }, \n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    dataframe = pd.merge(\n",
    "        dataframe,\n",
    "        it_annotation_results_df[[\n",
    "            \"apk\", \"version\", \n",
    "            \"it_mentioned_by_policy\", \"adequacy_decision_by_policy\", \"countries_mentioned_by_policy\"\n",
    "        ]], \n",
    "        on=[\"apk\", \"version\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    dataframe.fillna(\n",
    "        value={\n",
    "            \"countries_mentioned_by_policy\": \"[]\",\n",
    "            \"it_mentioned_by_policy\": False,\n",
    "            \"adequacy_decision_by_policy\": False\n",
    "        }, inplace=True\n",
    "    )\n",
    "    \n",
    "    return dataframe\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.423038Z",
     "start_time": "2024-03-13T22:32:04.419512Z"
    }
   },
   "id": "4b79f08eb4c84797",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with the info about the libraries which carried out the communication "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da2d74b9a83b5b19"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def populate_dataset_with_libraries_data(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    tpls_results_df = pd.read_csv(TPLS_RESULTS_FILEPATH, sep=\",\")\n",
    "    \n",
    "    dataframe = pd.merge(\n",
    "        dataframe,\n",
    "        tpls_results_df[[\n",
    "            \"apk\", \"version\", \"stackTrace\", \"ip_dest\",\n",
    "            \"TP-performed\", \"TP-library\", \"FP-intended\"\n",
    "        ]],\n",
    "        on=[\"apk\", \"version\", \"stackTrace\", \"ip_dest\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    \n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.427177Z",
     "start_time": "2024-03-13T22:32:04.424240Z"
    }
   },
   "id": "f4c048778787baae",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check GDPR compliance in terms of international transfers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a790c34e9a0bfc98"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_apk_it_gdpr_compliance(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe[\"apk_it_gdpr_compliance\"] = True\n",
    "    \n",
    "    dataframe[\"apk_it_gdpr_compliance\"] = dataframe.apply(\n",
    "        lambda row_to_check: \n",
    "        set(literal_eval(row_to_check[\"destinations_transfers_outside_EEE\"])).issubset(\n",
    "            set(literal_eval(row_to_check[\"countries_mentioned_by_policy\"]))\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return dataframe\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.434535Z",
     "start_time": "2024-03-13T22:32:04.429542Z"
    }
   },
   "id": "918ecd5bac3f9b42",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregate analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "afd295a3dbb8c704"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def aggregate_analysis(dataframe: pd.DataFrame, to_filepath: str):\n",
    "    aggregation_df = dataframe[\n",
    "        [\"apk\", \"version\", \"phase\", \n",
    "         \"tls\", \"https\", \"host\", \"ip_dest\", \n",
    "         \"PII\", \"ip_anycast\", \n",
    "         \"origins_transfers_outside_EEE\", \"destinations_transfers_outside_EEE\", \"frequency_transfers_outside_EEE\", \"outside_EEE\",\n",
    "         \"android_rating\", \"android_numDownloads\", \"android_category\", \n",
    "         \"countries_mentioned_by_policy\", \"it_mentioned_by_policy\", \"adequacy_decision_by_policy\", \"apk_it_gdpr_compliance\"]\n",
    "    ].copy()\n",
    "    \n",
    "    aggregation_df.drop_duplicates(inplace=True)\n",
    "\n",
    "    aggregation_df.fillna(\n",
    "        value={\n",
    "            \"countries_mentioned_by_policy\": \"[]\",\n",
    "            \"it_mentioned_by_policy\": False,\n",
    "            \"adequacy_decision_by_policy\": False\n",
    "        }, inplace=True\n",
    "    )\n",
    "    \n",
    "    aggregation_df.to_csv(to_filepath, sep=\",\", index=False)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:04.442957Z",
     "start_time": "2024-03-13T22:32:04.438822Z"
    }
   },
   "id": "b0effef8193a7b8e",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute the enrichment of data and generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f23ffaf42779f8b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Charge the dataframes to be used\n",
    "traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_FILEPATH, sep=\",\")\n",
    "anycast_pii_traffic_logs_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_FILEPATH, sep=\",\")\n",
    "datasets = [traffic_logs_ip_classified_analysis_df, anycast_pii_traffic_logs_df]\n",
    "analysis_filepaths = [TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:06.019314Z",
     "start_time": "2024-03-13T22:32:04.473007Z"
    }
   },
   "id": "ca54aaa1dc002700",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Because is a long process and is only necessary to run once I include the condition\n",
    "if GENERATE_ROUTES_DATA:\n",
    "    # Generate the results\n",
    "    generate_routes_raw()\n",
    "    generate_routes_frequency_aggregation()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-13T22:32:06.029146Z",
     "start_time": "2024-03-13T22:32:06.020795Z"
    }
   },
   "id": "1b453eecfba99303",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Populate datasets\n",
    "for index in range(0, len(datasets)):\n",
    "    dataset_to_improve = datasets[index]\n",
    "    \n",
    "    # Populate with routes\n",
    "    print(\"Populate with routes\")\n",
    "    dataset_to_improve = populate_dataset_with_routes_results(dataset_to_improve)\n",
    "    # Populate with metadata\n",
    "    print(\"Populate with metadata\")\n",
    "    dataset_to_improve = populate_dataset_with_apks_metadata(dataset_to_improve)\n",
    "    # Populate with the privacy policy extracted data\n",
    "    print(\"Populate with the privacy policy extracted data\")\n",
    "    dataset_to_improve = populate_dataset_with_policy_extracted_info(dataset_to_improve)\n",
    "    # Populate with libraries data\n",
    "    print(\"Populate with the libraries data\")\n",
    "    populate_dataset_with_libraries_data(dataset_to_improve)\n",
    "\n",
    "    # Check conditions\n",
    "    print(\"Checking IT declarations accomplishment\")\n",
    "    check_apk_it_gdpr_compliance(dataset_to_improve)\n",
    "    \n",
    "    dataset_to_improve.to_csv(analysis_filepaths[index], sep=\",\", index=False)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47809ecc512817c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis questions\n",
    "\n",
    "Answers to the questions needed for the article\n",
    "\n",
    "Acronyms:\n",
    "- PII = Personal Identificable Information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bd3273fca7aeeaa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data load\n",
    "traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, sep=\",\")\n",
    "anycast_pii_traffic_logs_analysis_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH, sep=\",\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4312ee087eaabf53",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**IPs analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88555225610e9127"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "ips_total = traffic_logs_ip_classified_analysis_df[\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs in traffic logs: {len(ips_total)}\")\n",
    "\n",
    "ips_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs with PII: {len(ips_total_pii)}\")\n",
    "\n",
    "ips_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs anycast: {len(ips_anycast)}\")\n",
    "\n",
    "ips_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs anycast with PII: {len(ips_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a95eaa1142c4f4b8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**APKS analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a71b37155d0389f5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "apks_total = traffic_logs_ip_classified_analysis_df[\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs in traffic logs: {len(apks_total)}\")\n",
    "\n",
    "apks_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs with PII: {len(apks_total_pii)}\")\n",
    "\n",
    "apks_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs using anycast: {len(apks_anycast)}\")\n",
    "\n",
    "apks_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs anycast with PII: {len(apks_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c72f39cb6c7d85",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hosts Analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98ce9aa4f43b5d2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "hosts_total = traffic_logs_ip_classified_analysis_df[\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts in traffic logs: {len(hosts_total)}\")\n",
    "\n",
    "hosts_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts with PII: {len(hosts_total_pii)}\")\n",
    "\n",
    "hosts_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts using anycast: {len(hosts_anycast)}\")\n",
    "\n",
    "hosts_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts anycast with PII: {len(hosts_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a9bcccc70a378d",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Types**  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22eacec4072b9aef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pii_data_types_anycast = anycast_pii_traffic_logs_analysis_df[\"PII\"].unique().tolist()\n",
    "print(f\"Types of PII data treated by anycast IPs:\")\n",
    "print(pii_data_types_anycast)\n",
    "\n",
    "pii_data_types_anycast_pii_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"]\n",
    "][\"PII\"].unique().tolist()\n",
    "print(f\"Types of PII data treated by anycast IPs that make IT:\")\n",
    "print(pii_data_types_anycast_pii_it)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c27f5d9f8c7fe13b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**GDPR Compliance**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d554e1ce805ee86"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "apks_anycast_pii_declare_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"it_mentioned_by_policy\"]\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that declare IT in privacy policy: {len(apks_anycast_pii_declare_it)}\")\n",
    "\n",
    "apks_anycast_pii_not_compliance = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"apk_it_gdpr_compliance\"] == False\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that has not compliance: {len(apks_anycast_pii_not_compliance)}\")\n",
    "\n",
    "apks_anycast_pii_not_compliance_declare_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"it_mentioned_by_policy\"] == True) &\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"apk_it_gdpr_compliance\"] == False)\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that has not compliance and declare IT in privacy policy: {len(apks_anycast_pii_not_compliance_declare_it)}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39f65ca46cf5f6ec",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TLPs**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772e34f4c4130bdc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(\"Libraries\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6c757064eb2128f3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STOP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9361948247880a97"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear datos aleatorios para el DataFrame\n",
    "data_total = {\n",
    "    'numeros': np.random.randint(0, 100, 10),\n",
    "    'decimales': np.random.randn(10),\n",
    "    'letras': np.random.choice(['A', 'B'], 10),\n",
    "    'booleanos': np.random.choice([True, False], 10)\n",
    "}\n",
    "\n",
    "data_spec = {\n",
    "    'decimales': np.random.randn(10),\n",
    "    'letras': np.random.choice(['A', 'B'], 10),\n",
    "    'booleanos': np.random.choice([True, False], 10)\n",
    "}\n",
    "\n",
    "# Crear el DataFrame\n",
    "df_total = pd.DataFrame(data_total)\n",
    "df_spec = pd.DataFrame(data_spec)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d941a1e228b8ab7e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df_total)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4ca50d4b7c9b368d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(df_spec)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73eaf773dae2c0ba"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def function_test(df):\n",
    "    return df.merge(df_spec[[\"letras\", \"booleanos\"]], on=[\"letras\"], how='left').copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de1b5888ccf5ef57"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_total = function_test(df_total)\n",
    "df_total\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce3fdc8a8aa99b3c",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
