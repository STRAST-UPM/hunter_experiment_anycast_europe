{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment Mesh Analysis\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ecc4b83731736b"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# external imports\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from shapely import (\n",
    "    from_geojson\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.097579241Z",
     "start_time": "2024-04-01T20:36:21.729005570Z"
    }
   },
   "id": "c8df69fe46cac602"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# internal imports\n",
    "from src.utils.common_functions import (\n",
    "    json_file_to_dict,\n",
    "    get_list_files_in_path,\n",
    ")\n",
    "from src.utils.constants import (\n",
    "    EEE_COUNTRIES_FILEPATH,\n",
    "    REPLICATION_PACKAGE_DIR,\n",
    "    TRAFFIC_LOGS_IP_CLASSIFIED_FILEPATH,\n",
    "    ANYCAST_PII_TRAFFIC_LOGS_FILEPATH,\n",
    "    APKS_METADATA_FILEPATH,\n",
    "    RESULTS_MODES,\n",
    "    IT_ANNOTATION_FILEPATH,\n",
    "    TPLS_RESULTS_FILEPATH,\n",
    "    ANYCAST_IP_CLASSIFICATION_FILEPATH\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.133237260Z",
     "start_time": "2024-04-01T20:36:21.999970045Z"
    }
   },
   "id": "69d16f8da4f9071f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Constants\n",
    "EEE_countries_set = set([country[\"alpha-2\"] for country in json_file_to_dict(EEE_COUNTRIES_FILEPATH)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.423416828Z",
     "start_time": "2024-04-01T20:36:22.135879107Z"
    }
   },
   "id": "adb458e6157c0f69"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Analysis params\n",
    "DESTINATION_REPETITIONS_LIMIT = 1\n",
    "ANALYSIS_MODE=RESULTS_MODES[0]\n",
    "GENERATE_ROUTES_DATA=False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.507177635Z",
     "start_time": "2024-04-01T20:36:22.407950571Z"
    }
   },
   "id": "690c1391498feefb"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Filepaths variables\n",
    "EXPERIMENT_RESULTS_FOLDER = f\"{REPLICATION_PACKAGE_DIR}/experiment_results_{ANALYSIS_MODE}\"\n",
    "ANALYSIS_FOLDER = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}\"\n",
    "\n",
    "ROUTES_RESULTS_FILENAME = f\"{ANALYSIS_FOLDER}/routes_results_{ANALYSIS_MODE}.csv\"\n",
    "ROUTES_FREQUENCY_FILENAME = f\"{ANALYSIS_FOLDER}/routes_frequency_{ANALYSIS_MODE}.csv\"\n",
    "\n",
    "ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Anycast_PII_Traffic_Logs_{ANALYSIS_MODE}.csv\"\n",
    "TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Traffic_logs_10K_ip_classified_{ANALYSIS_MODE}.csv\"\n",
    "\n",
    "ANYCAST_PII_HOST_AGGREGATION_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Anycast_PII_host_aggregation_{ANALYSIS_MODE}.csv\"\n",
    "TRAFFIC_LOGS_IP_CLASSIFIED_HOST_AGGREGATION_FILEPATH = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}/Traffic_logs_10K_ip_classified_host_aggregation_{ANALYSIS_MODE}.csv\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.666043007Z",
     "start_time": "2024-04-01T20:36:22.446129778Z"
    }
   },
   "id": "759dc69c48ceb4bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Enrichment of data and generation of datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50b5569c9c01bcd1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Auxiliar just if needed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee77ee73a524612d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def populate_dataframe_with_ip_classification(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    ips_classified = json_file_to_dict(ANYCAST_IP_CLASSIFICATION_FILEPATH)\n",
    "\n",
    "    for ip_classified in ips_classified.keys():\n",
    "        dataframe.loc[dataframe[\"ip_dest\"] == ip_classified, \"ip_anycast\"] = ips_classified[ip_classified]\n",
    "    \n",
    "    return dataframe    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.718200842Z",
     "start_time": "2024-04-01T20:36:22.674727710Z"
    }
   },
   "id": "1c22e353dec78f8b",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate a file with all the routes got as the result of the experiment execution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "829bbc8293d73e11"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Auxiliary functions\n",
    "def get_probe_location(probe_id: int, origin_list: []) -> (float, float):\n",
    "    for origin in origin_list:\n",
    "        if probe_id == origin[\"probe_id\"]:\n",
    "            location = from_geojson(origin[\"location\"])\n",
    "            return location.y, location.x\n",
    "        else:\n",
    "            continue\n",
    "    return 0, 0\n",
    "\n",
    "def get_result_country_route(hunter_result: dict) -> dict:\n",
    "    probe_id = hunter_result[\"origin_id\"]\n",
    "    result_country = hunter_result[\"location_result\"][\"country\"]\n",
    "    probe_country = hunter_result[\"origin_country_code\"]\n",
    "\n",
    "    return {\n",
    "        \"origin_id\": probe_id,\n",
    "        \"origin_country\": probe_country,\n",
    "        \"result_country\": result_country\n",
    "    }\n",
    "\n",
    "# Data generation function\n",
    "def generate_routes_raw():\n",
    "    routes_raw_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"target\", \"probe_id\", \"ips_previous_to_target\",\n",
    "            \"origin_country\", \"origin_latitude\", \"origin_longitude\", \n",
    "            \"result_country\", \"result_latitude\", \"result_longitude\",\n",
    "            \"result_filename\", \"outside_EEE\"\n",
    "        ]\n",
    "    )\n",
    "    for result_filename in get_list_files_in_path(EXPERIMENT_RESULTS_FOLDER):\n",
    "        print(result_filename)\n",
    "        result = json_file_to_dict(f\"{EXPERIMENT_RESULTS_FOLDER}/{result_filename}\")\n",
    "        target = result[\"target\"]\n",
    "        origin_list = result[\"measurements\"][\"origin\"]\n",
    "        for hunter_result in result[\"hunter_results\"]:\n",
    "            route = get_result_country_route(hunter_result)\n",
    "            probe_id = hunter_result[\"origin_id\"]\n",
    "            origin_country = route[\"origin_country\"]\n",
    "            origin_latitude, origin_longitude = get_probe_location(probe_id, origin_list)\n",
    "            \n",
    "            result_country = route[\"result_country\"]\n",
    "            if len(hunter_result[\"location_result\"][\"airports_intersection\"]) == 1:\n",
    "                result_location = from_geojson(hunter_result[\"location_result\"][\"airports_intersection\"][0][\"location\"])\n",
    "                result_latitude = result_location.y\n",
    "                result_longitude = result_location.x\n",
    "            else:\n",
    "                result_latitude = 0\n",
    "                result_longitude = 0\n",
    "                \n",
    "            outside_eee = (result_country not in EEE_countries_set) and (result_country != \"Indeterminate\")\n",
    "            \n",
    "            if result_country == \"Indeterminate\":\n",
    "                ips_previous_to_target = [\"Indeterminate\"]\n",
    "            else:\n",
    "                ips_previous_to_target = [\n",
    "                    ip[\"ip\"]\n",
    "                    for ip in hunter_result[\"ips_previous_to_target\"]\n",
    "                ]\n",
    "            \n",
    "            routes_raw_df = pd.concat(\n",
    "                [pd.DataFrame([[\n",
    "                    target, probe_id, str(ips_previous_to_target),\n",
    "                    origin_country, origin_latitude, origin_longitude, \n",
    "                    result_country, result_latitude, result_longitude,\n",
    "                    result_filename, outside_eee\n",
    "                ]], columns=routes_raw_df.columns), routes_raw_df], \n",
    "                ignore_index=True\n",
    "            )\n",
    "    # Sort and save\n",
    "    routes_raw_df.sort_values(by=[\"target\", \"origin_country\", \"result_country\"], inplace=True)\n",
    "    routes_raw_df.to_csv(ROUTES_RESULTS_FILENAME, sep=\",\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.904364971Z",
     "start_time": "2024-04-01T20:36:22.717873153Z"
    }
   },
   "id": "3a4a5ff135ebc9cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregate and count routes repetitions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2905481c5a38b1ac"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Data generation function\n",
    "def generate_routes_frequency_aggregation():\n",
    "    # Aggregate routes counting the repetitions\n",
    "    routes_frequency_df = pd.read_csv(ROUTES_RESULTS_FILENAME, sep=\",\")\n",
    "    routes_frequency_df = routes_frequency_df[[\"target\", \"origin_country\", \"result_country\"]]\n",
    "    routes_frequency_df = routes_frequency_df.value_counts(subset=['target', 'origin_country', 'result_country'])\n",
    "    routes_frequency_df.to_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\")\n",
    "    \n",
    "    # Include the info about outside the EEE\n",
    "    routes_frequency_df = pd.read_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\")\n",
    "    routes_frequency_df[\"outside_EEE\"] = False\n",
    "    \n",
    "    routes_frequency_df.loc[\n",
    "        (routes_frequency_df[\"result_country\"] != \"Indeterminate\") &\n",
    "        (~routes_frequency_df[\"result_country\"].isin(EEE_countries_set)),\n",
    "        [\"outside_EEE\"]\n",
    "    ] = True\n",
    "    routes_frequency_df.to_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:22.909650036Z",
     "start_time": "2024-04-01T20:36:22.878571443Z"
    }
   },
   "id": "1ef13530479b1cbb",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Introduce routes outside EEE and its count in the complete dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51ebb6a53d3489d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Dataset population function\n",
    "def populate_dataset_with_routes_results(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    routes_valid_df = pd.read_csv(ROUTES_FREQUENCY_FILENAME, sep=\",\")\n",
    "    routes_valid_df = routes_valid_df.loc[\n",
    "        (routes_valid_df[\"outside_EEE\"] == True) & \n",
    "        (routes_valid_df[\"count\"] >= DESTINATION_REPETITIONS_LIMIT)\n",
    "    ]\n",
    "\n",
    "    # Charge default routes in the dataset to populate\n",
    "    dataframe[\"origins_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"destinations_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"frequency_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"outside_EEE\"] = False\n",
    "    \n",
    "    # For every IP get the list of origins, destinations and frequency and save it\n",
    "    for ip in routes_valid_df[\"target\"].unique().tolist():\n",
    "        ip_routes = routes_valid_df.loc[routes_valid_df[\"target\"] == ip]\n",
    "        origins_transfers_outside_eee = ip_routes[\"origin_country\"].values.tolist()\n",
    "        destinations_transfers_outside_eee = ip_routes[\"result_country\"].values.tolist()\n",
    "        frequency_transfers_outside_eee = ip_routes[\"count\"].values.tolist()\n",
    "\n",
    "        dataframe.loc[\n",
    "            (dataframe[\"ip_dest\"] == ip), \n",
    "            [\"origins_transfers_outside_EEE\", \n",
    "             \"destinations_transfers_outside_EEE\", \n",
    "             \"frequency_transfers_outside_EEE\",\n",
    "             \"outside_EEE\"]\n",
    "        ] = [str(origins_transfers_outside_eee),\n",
    "             str(destinations_transfers_outside_eee),\n",
    "             str(frequency_transfers_outside_eee),\n",
    "             True]\n",
    "    \n",
    "    return dataframe\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:23.009421220Z",
     "start_time": "2024-04-01T20:36:22.918479819Z"
    }
   },
   "id": "c5fdd5566a17a165",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with metadata info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4e872e6e4f5f347"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def populate_dataset_with_apks_metadata(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    apk_metadata_df = pd.read_csv(APKS_METADATA_FILEPATH, sep=\",\")\n",
    "    \n",
    "    return dataframe.merge(\n",
    "        apk_metadata_df,\n",
    "        on=[\"apk\", \"version\"],\n",
    "        how=\"left\"\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:23.010879619Z",
     "start_time": "2024-04-01T20:36:22.984900471Z"
    }
   },
   "id": "6b1c5cf65806854e",
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with the info extrated from every policy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cce1d5fd8c0c621b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def populate_dataset_with_policy_extracted_info(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    it_annotation_results_df = pd.read_csv(IT_ANNOTATION_FILEPATH, sep=\",\")\n",
    "    \n",
    "    it_annotation_results_df.drop_duplicates([\"apk\", \"countries\"], inplace=True)\n",
    "    it_annotation_results_df.rename(\n",
    "        columns={\n",
    "            \"transfer\": \"it_mentioned_by_policy\",\n",
    "            \"adequacy_decision\": \"adequacy_decision_by_policy\",\n",
    "            \"countries\": \"countries_mentioned_by_policy\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    dataframe = pd.merge(\n",
    "        dataframe,\n",
    "        it_annotation_results_df[[\n",
    "            \"apk\", \"version\", \n",
    "            \"it_mentioned_by_policy\", \"adequacy_decision_by_policy\", \"countries_mentioned_by_policy\"\n",
    "        ]], \n",
    "        on=[\"apk\", \"version\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    dataframe.fillna(\n",
    "        value={\n",
    "            \"it_mentioned_by_policy\": False,\n",
    "            \"adequacy_decision_by_policy\": False,\n",
    "            \"countries_mentioned_by_policy\": \"[]\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )    \n",
    "    return dataframe\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:23.074044813Z",
     "start_time": "2024-04-01T20:36:23.025067036Z"
    }
   },
   "id": "4b79f08eb4c84797",
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with the info about the libraries which carried out the communication "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da2d74b9a83b5b19"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def populate_dataset_with_libraries_data(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    tpls_results_df = pd.read_csv(TPLS_RESULTS_FILEPATH, sep=\",\")\n",
    "    tpls_results_df.fillna(\n",
    "        {\n",
    "            \"TP-performed\": False,\n",
    "            \"TP-library\": \"None\",\n",
    "            \"FP-intended\": False,\n",
    "        }, inplace=True\n",
    "    )\n",
    "    \n",
    "    dataframe = pd.merge(\n",
    "        dataframe,\n",
    "        tpls_results_df[[\n",
    "            \"apk\", \"version\", \"port_source\", \"host\", \"port_dest\", \"ip_dest\",\n",
    "            \"TP-performed\", \"TP-library\", \"FP-intended\"\n",
    "        ]],\n",
    "        on=[\"apk\", \"version\", \"port_source\", \"host\", \"port_dest\", \"ip_dest\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:23.096589594Z",
     "start_time": "2024-04-01T20:36:23.040195823Z"
    }
   },
   "id": "f4c048778787baae",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check GDPR compliance in terms of international transfers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a790c34e9a0bfc98"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def check_apk_it_gdpr_compliance(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe[\"apk_it_gdpr_compliance\"] = True\n",
    "    \n",
    "    dataframe[\"apk_it_gdpr_compliance\"] = dataframe.apply(\n",
    "        lambda row_to_check: \n",
    "        set(literal_eval(row_to_check[\"destinations_transfers_outside_EEE\"])).issubset(\n",
    "            set(literal_eval(row_to_check[\"countries_mentioned_by_policy\"]))\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return dataframe\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:23.098341513Z",
     "start_time": "2024-04-01T20:36:23.074416503Z"
    }
   },
   "id": "918ecd5bac3f9b42",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregation of apk and destination IP by domain or host"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88534750de51daa3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def aggregate_by_domain(dataframe: pd.DataFrame, filepath: str):\n",
    "    group_df = dataframe[[\"host\", \"ip_dest\", \"apk\"]]\n",
    "    group_df = group_df.groupby([\"host\", \"ip_dest\", \"apk\"]).size().reset_index(name=\"traffic_logs\")\n",
    "\n",
    "    group_df.sort_values(by=[\"host\", \"apk\", \"ip_dest\"], inplace=True)\n",
    "    \n",
    "    group_df.to_csv(filepath, sep=\",\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:23.146419101Z",
     "start_time": "2024-04-01T20:36:23.097162694Z"
    }
   },
   "id": "64f7bf6493d860f6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Execute the enrichment of data and generation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f23ffaf42779f8b"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Because is a long process and is only necessary to run once I include the condition\n",
    "if GENERATE_ROUTES_DATA:\n",
    "    # Generate the results\n",
    "    generate_routes_raw()\n",
    "    generate_routes_frequency_aggregation()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:23.166333304Z",
     "start_time": "2024-04-01T20:36:23.140988776Z"
    }
   },
   "id": "b6206031db89a758"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make the analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f7d4fdd4cf15c54"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Charge the dataframes to be used\n",
    "traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_FILEPATH, sep=\",\")\n",
    "anycast_pii_traffic_logs_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_FILEPATH, sep=\",\")\n",
    "datasets = [traffic_logs_ip_classified_analysis_df, anycast_pii_traffic_logs_df]\n",
    "analysis_filepaths = [TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH]\n",
    "aggregation_filepaths = [TRAFFIC_LOGS_IP_CLASSIFIED_HOST_AGGREGATION_FILEPATH, ANYCAST_PII_HOST_AGGREGATION_FILEPATH]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:36:24.504231194Z",
     "start_time": "2024-04-01T20:36:23.156917492Z"
    }
   },
   "id": "ca54aaa1dc002700",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate with metadata\n",
      "Populate with the privacy policy extracted data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18507/2212109401.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataframe.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate with routes\n",
      "Populate with the libraries data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18507/3888633032.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tpls_results_df.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking IT declarations accomplishment\n",
      "Setting types and NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18507/1528222652.py:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset_to_improve.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n",
      "Populate with metadata\n",
      "Populate with the privacy policy extracted data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18507/2212109401.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataframe.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate with routes\n",
      "Populate with the libraries data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18507/3888633032.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tpls_results_df.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking IT declarations accomplishment\n",
      "Setting types and NaN\n",
      "Saving data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18507/1528222652.py:23: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset_to_improve.fillna(\n"
     ]
    }
   ],
   "source": [
    "# Populate datasets\n",
    "for index in range(0, len(datasets)):\n",
    "    dataset_to_improve = datasets[index]\n",
    "    \n",
    "    # Populate with metadata\n",
    "    print(\"Populate with metadata\")\n",
    "    dataset_to_improve = populate_dataset_with_apks_metadata(dataset_to_improve)\n",
    "    # Populate with the privacy policy extracted data\n",
    "    print(\"Populate with the privacy policy extracted data\")\n",
    "    dataset_to_improve = populate_dataset_with_policy_extracted_info(dataset_to_improve)\n",
    "    # Populate with routes\n",
    "    print(\"Populate with routes\")\n",
    "    dataset_to_improve = populate_dataset_with_routes_results(dataset_to_improve)\n",
    "    # Populate with libraries data\n",
    "    print(\"Populate with the libraries data\")\n",
    "    dataset_to_improve = populate_dataset_with_libraries_data(dataset_to_improve)\n",
    "\n",
    "    # Check conditions\n",
    "    print(\"Checking IT declarations accomplishment\")\n",
    "    dataset_to_improve = check_apk_it_gdpr_compliance(dataset_to_improve)\n",
    "\n",
    "    print(\"Setting types and NaN\")\n",
    "    dataset_to_improve.fillna(\n",
    "        {\n",
    "            \"loadsJNI\": False,\n",
    "            \"stackTrace\": \"None\",\n",
    "            \"remote_host\": \"None\",\n",
    "            \"tls\": False,\n",
    "            \"https\": False,\n",
    "            \"error\": \"None\",\n",
    "            \"TP-performed\": False,\n",
    "            \"TP-library\": \"None\",\n",
    "            \"FP-intended\": False,\n",
    "        }, inplace=True\n",
    "    )\n",
    "    \n",
    "    print(\"Saving data\")\n",
    "    dataset_to_improve.to_csv(analysis_filepaths[index], sep=\",\", index=False)\n",
    "    \n",
    "    # Generate the aggregations for better understanding\n",
    "    aggregate_by_domain(dataframe=dataset_to_improve, filepath=aggregation_filepaths[index])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:39:57.623162294Z",
     "start_time": "2024-04-01T20:36:24.545062169Z"
    }
   },
   "id": "47809ecc512817c",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis questions\n",
    "\n",
    "Answers to the questions needed for the article\n",
    "\n",
    "Acronyms:\n",
    "- PII = Personal Identificable Information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bd3273fca7aeeaa"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18507/3233838539.py:2: DtypeWarning: Columns (7,9,24,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, sep=\",\")\n",
      "/tmp/ipykernel_18507/3233838539.py:3: DtypeWarning: Columns (37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  anycast_pii_traffic_logs_analysis_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH, sep=\",\")\n"
     ]
    }
   ],
   "source": [
    "# Data load\n",
    "traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, sep=\",\")\n",
    "anycast_pii_traffic_logs_analysis_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH, sep=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:20.725273356Z",
     "start_time": "2024-04-01T20:39:57.629749088Z"
    }
   },
   "id": "4312ee087eaabf53",
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "Traffic numbers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d12092a81d77b8"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connections intercepted: 4278823\n",
      "Number of anycast connections intercepted: 195786\n"
     ]
    }
   ],
   "source": [
    "all_connections = len(traffic_logs_ip_classified_analysis_df.index)\n",
    "print(f\"Number of connections intercepted: {all_connections}\")\n",
    "\n",
    "anycast_connections = len(anycast_pii_traffic_logs_analysis_df.index)\n",
    "print(f\"Number of anycast connections intercepted: {anycast_connections}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:20.772964293Z",
     "start_time": "2024-04-01T20:40:20.724045162Z"
    }
   },
   "id": "1c718eb434f411c7",
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "**IPs analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88555225610e9127"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IPs in traffic logs: 5647\n",
      "Number of IPs with PII: 1807\n",
      "Number of IPs anycast: 991\n",
      "Number of IPs anycast with PII: 200\n"
     ]
    }
   ],
   "source": [
    "ips_total = traffic_logs_ip_classified_analysis_df[\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs in traffic logs: {len(ips_total)}\")\n",
    "\n",
    "ips_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs with PII: {len(ips_total_pii)}\")\n",
    "\n",
    "ips_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs anycast: {len(ips_anycast)}\")\n",
    "\n",
    "ips_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs anycast with PII: {len(ips_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:23.236566062Z",
     "start_time": "2024-04-01T20:40:20.733138744Z"
    }
   },
   "id": "a95eaa1142c4f4b8",
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "**APKS analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a71b37155d0389f5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of APKs in traffic logs: 5759\n",
      "Number of APKs with PII: 3478\n",
      "Number of APKs using anycast: 1669\n",
      "Number of APKs anycast with PII: 960\n"
     ]
    }
   ],
   "source": [
    "apks_total = traffic_logs_ip_classified_analysis_df[\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs in traffic logs: {len(apks_total)}\")\n",
    "\n",
    "apks_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs with PII: {len(apks_total_pii)}\")\n",
    "\n",
    "apks_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs using anycast: {len(apks_anycast)}\")\n",
    "\n",
    "apks_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs anycast with PII: {len(apks_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:26.031205865Z",
     "start_time": "2024-04-01T20:40:23.334196806Z"
    }
   },
   "id": "76c72f39cb6c7d85",
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hosts Analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98ce9aa4f43b5d2"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hosts in traffic logs: 4738\n",
      "Number of hosts with PII: 966\n",
      "Number of hosts using anycast: 995\n",
      "Number of hosts anycast with PII: 201\n"
     ]
    }
   ],
   "source": [
    "hosts_total = traffic_logs_ip_classified_analysis_df[\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts in traffic logs: {len(hosts_total)}\")\n",
    "\n",
    "hosts_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts with PII: {len(hosts_total_pii)}\")\n",
    "\n",
    "hosts_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts using anycast: {len(hosts_anycast)}\")\n",
    "\n",
    "hosts_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts anycast with PII: {len(hosts_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:28.503821200Z",
     "start_time": "2024-04-01T20:40:26.475635864Z"
    }
   },
   "id": "5a9bcccc70a378d",
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Types**  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22eacec4072b9aef"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of PII data treated by anycast IPs:\n",
      "['Device_Model', 'Google_Ad_ID', 'Build_No', 'Kernel_version', 'Fingerprint', 'Router_Wifi_BSSID', 'Router_Wifi_BSSID_Close', 'Router_Wifi_MAC', 'Device_location', 'Device_location_coarse']\n",
      "Types of PII data treated by anycast IPs that make IT:\n",
      "['Device_Model', 'Google_Ad_ID', 'Build_No', 'Kernel_version', 'Fingerprint', 'Router_Wifi_BSSID', 'Router_Wifi_BSSID_Close', 'Router_Wifi_MAC', 'Device_location', 'Device_location_coarse']\n"
     ]
    }
   ],
   "source": [
    "pii_data_types_anycast = anycast_pii_traffic_logs_analysis_df[\"PII\"].unique().tolist()\n",
    "print(f\"Types of PII data treated by anycast IPs:\")\n",
    "print(pii_data_types_anycast)\n",
    "\n",
    "pii_data_types_anycast_pii_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"]\n",
    "][\"PII\"].unique().tolist()\n",
    "print(f\"Types of PII data treated by anycast IPs that make IT:\")\n",
    "print(pii_data_types_anycast_pii_it)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:28.610778139Z",
     "start_time": "2024-04-01T20:40:28.509490370Z"
    }
   },
   "id": "c27f5d9f8c7fe13b",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "**GDPR Compliance**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d554e1ce805ee86"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of APKs that use anycast IPs and treat PII that declare IT in privacy policy: 196\n",
      "Number of APKs that use anycast IPs and treat PII that has not compliance: 947\n",
      "Number of APKs that use anycast IPs and treat PII that has not compliance and declare IT in privacy policy: 189\n"
     ]
    }
   ],
   "source": [
    "apks_anycast_pii_declare_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"it_mentioned_by_policy\"]\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that declare IT in privacy policy: {len(apks_anycast_pii_declare_it)}\")\n",
    "\n",
    "apks_anycast_pii_not_compliance = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"apk_it_gdpr_compliance\"] == False\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that has not compliance: {len(apks_anycast_pii_not_compliance)}\")\n",
    "\n",
    "apks_anycast_pii_not_compliance_declare_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"it_mentioned_by_policy\"] == True) &\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"apk_it_gdpr_compliance\"] == False)\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that has not compliance and declare IT in privacy policy: {len(apks_anycast_pii_not_compliance_declare_it)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:28.661370543Z",
     "start_time": "2024-04-01T20:40:28.573642964Z"
    }
   },
   "id": "39f65ca46cf5f6ec",
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TLPs**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772e34f4c4130bdc"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connections Anycast+PII: 195786\n",
      "Number of connections Anycast+PII+IT: 195432\n",
      "Number of connections Anycast+PII+IT set up by APP: 89103\n",
      "Number of connections Anycast+PII+IT unknow: 0\n",
      "Number of connections Anycast+PII+IT set up by TPL: 83833\n",
      "Number of connections Anycast+PII+IT set up by TPL but performed from FP: 77873\n"
     ]
    }
   ],
   "source": [
    "anycast_pii_connections = len(anycast_pii_traffic_logs_analysis_df.index)\n",
    "print(f\"Number of connections Anycast+PII: {anycast_pii_connections}\")\n",
    "\n",
    "anycast_pii_it_connections = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True)\n",
    "    ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT: {anycast_pii_it_connections}\")\n",
    "\n",
    "anycast_pii_it_connections_by_app = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"TP-performed\"] == False) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"FP-intended\"] == True)\n",
    "    ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT set up by APP: {anycast_pii_it_connections_by_app}\")\n",
    "\n",
    "anycast_pii_it_connections_unknown = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"TP-performed\"] == False) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"TP-library\"] == \"None\") &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"FP-intended\"] == False)\n",
    "        ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT unknow: {anycast_pii_it_connections_unknown}\")\n",
    "\n",
    "anycast_pii_it_connections_by_tpl = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"TP-performed\"] == True)\n",
    "        ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT set up by TPL: {anycast_pii_it_connections_by_tpl}\")\n",
    "\n",
    "anycast_pii_it_connections_by_tpl_fp_intended = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"TP-performed\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"FP-intended\"] == True)\n",
    "        ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT set up by TPL but performed from FP: {anycast_pii_it_connections_by_tpl_fp_intended}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:28.778526958Z",
     "start_time": "2024-04-01T20:40:28.662297818Z"
    }
   },
   "id": "6c757064eb2128f3",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of TPLs Anycast+PII+IT\n",
      "['com.google', 'com.unity3d', 'com.onesignal', 'com.mob', 'com.bugsnag', 'com.newrelic.agent.android', 'com.android.volley', 'com.adjust.sdk', 'io.bidmachine', 'com.appodeal.ads', 'com.applovin', 'com.mixpanel.android', 'com.google.android.gms', 'com.kochava.core', 'com.adcolony', 'com.safedk', 'com.chartboost', 'com.mopub.volley', 'io.sentry', 'com.urbanairship', 'com.emarsys', 'com.leanplum', 'com.kochava', 'com.fyber', 'io.grpc', 'com.dynatrace']\n",
      "Number of TPLs Anycast+PII+IT: 26\n"
     ]
    }
   ],
   "source": [
    "tpls_anycast_pii_ip = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"TP-library\"] != \"None\") &\n",
    "    (~anycast_pii_traffic_logs_analysis_df[\"TP-library\"].isnull())\n",
    "][\"TP-library\"].unique().tolist()\n",
    "\n",
    "print(\"List of TPLs Anycast+PII+IT\")\n",
    "print(tpls_anycast_pii_ip)\n",
    "print(f\"Number of TPLs Anycast+PII+IT: {len(tpls_anycast_pii_ip)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-01T20:40:28.834877422Z",
     "start_time": "2024-04-01T20:40:28.789645170Z"
    }
   },
   "id": "e3373c4dbe6b8191",
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "# STOP"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9361948247880a97"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
