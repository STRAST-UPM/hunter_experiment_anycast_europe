{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiment Mesh Analysis\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1ecc4b83731736b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports and constants declarations",
   "id": "2fc169be9fa6589f"
  },
  {
   "cell_type": "code",
   "source": [
    "# external imports\n",
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "from shapely import (\n",
    "    from_geojson\n",
    ")\n",
    "import ipaddress\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "from dotenv import load_dotenv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:00.977880Z",
     "start_time": "2024-05-09T10:06:00.674562Z"
    }
   },
   "id": "c8df69fe46cac602",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# internal imports\n",
    "from src.utils.common_functions import (\n",
    "    json_file_to_dict,\n",
    "    get_list_files_in_path\n",
    ")\n",
    "from src.utils.constants import (\n",
    "    EEE_COUNTRIES_FILEPATH,\n",
    "    REPLICATION_PACKAGE_DIR,\n",
    "    PARTIAL_RESULTS_DIR,\n",
    "    TRAFFIC_LOGS_IP_CLASSIFIED_FILEPATH,\n",
    "    ANYCAST_PII_TRAFFIC_LOGS_FILEPATH,\n",
    "    APKS_METADATA_FILEPATH,\n",
    "    RESULTS_MODES,\n",
    "    IT_ANNOTATION_FILEPATH,\n",
    "    TPLS_RESULTS_FILEPATH,\n",
    "    ANYCAST_IP_CLASSIFICATION_FILEPATH,\n",
    "    TPLS_MANUAL_POLICY_INFO,\n",
    "    TPLS_POLICY_ANALYSIS\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:00.982495Z",
     "start_time": "2024-05-09T10:06:00.979082Z"
    }
   },
   "id": "69d16f8da4f9071f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "load_dotenv(\"./src/utils/.env\")\n",
    "IP_URL = str(os.getenv(\"CACHE_IP_URL\")) or \"\"\n",
    "# Constants\n",
    "EEE_countries_set = set([country[\"alpha-2\"] for country in json_file_to_dict(EEE_COUNTRIES_FILEPATH)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:00.997480Z",
     "start_time": "2024-05-09T10:06:00.983288Z"
    }
   },
   "id": "adb458e6157c0f69",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Analysis params\n",
    "ANALYSIS_MODE=RESULTS_MODES[1]\n",
    "GENERATE_ROUTES_RAW = False\n",
    "GENERATE_ROUTES_ADDONS = True\n",
    "ANALYZE_DATA = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:01.007364Z",
     "start_time": "2024-05-09T10:06:00.998568Z"
    }
   },
   "id": "690c1391498feefb",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "# Filepaths variables\n",
    "EXPERIMENT_RESULTS_FOLDER = f\"{REPLICATION_PACKAGE_DIR}/experiment_results_{ANALYSIS_MODE}\"\n",
    "ANALYSIS_FOLDER = f\"{REPLICATION_PACKAGE_DIR}/analysis_{ANALYSIS_MODE}\"\n",
    "\n",
    "ROUTES_RESULTS_FILENAME = f\"{ANALYSIS_FOLDER}/routes_results_{ANALYSIS_MODE}.csv\"\n",
    "ROUTES_RESULTS_NON_SUSPICIOUS_FILENAME = f\"{ANALYSIS_FOLDER}/routes_results_non_suspicious_{ANALYSIS_MODE}.csv\"\n",
    "ROUTES_RESULTS_SUSPICIOUS_FILENAME = f\"{ANALYSIS_FOLDER}/routes_results_suspicious_{ANALYSIS_MODE}.csv\"\n",
    "ROUTES_FREQUENCY_FILENAME = f\"{ANALYSIS_FOLDER}/routes_frequency_{ANALYSIS_MODE}.csv\"\n",
    "ROUTES_FREQUENCY_NON_SUSPICIOUS_FILENAME = f\"{ANALYSIS_FOLDER}/routes_frequency_non_suspicious_{ANALYSIS_MODE}.csv\"\n",
    "ROUTES_FREQUENCY_SUSPICIOUS_FILENAME = f\"{ANALYSIS_FOLDER}/routes_frequency_suspicious_{ANALYSIS_MODE}.csv\"\n",
    "\n",
    "ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH = f\"{ANALYSIS_FOLDER}/Anycast_PII_Traffic_Logs_{ANALYSIS_MODE}.csv\"\n",
    "TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH = f\"{ANALYSIS_FOLDER}/Traffic_logs_10K_ip_classified_{ANALYSIS_MODE}.csv\"\n",
    "\n",
    "ANYCAST_PII_HOST_AGGREGATION_FILEPATH = f\"{ANALYSIS_FOLDER}/Anycast_PII_host_aggregation_{ANALYSIS_MODE}.csv\"\n",
    "TRAFFIC_LOGS_IP_CLASSIFIED_HOST_AGGREGATION_FILEPATH = f\"{ANALYSIS_FOLDER}/Traffic_logs_10K_ip_classified_host_aggregation_{ANALYSIS_MODE}.csv\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:01.018987Z",
     "start_time": "2024-05-09T10:06:01.008033Z"
    }
   },
   "id": "759dc69c48ceb4bd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": "## Extractions of data from results",
   "metadata": {
    "collapsed": false
   },
   "id": "50b5569c9c01bcd1"
  },
  {
   "cell_type": "markdown",
   "source": "The first operation is to extract the routes and relevant info from every hunter execution and obtain a complete dataset with the result to make the analysis.",
   "metadata": {
    "collapsed": false
   },
   "id": "ee77ee73a524612d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Auxiliar functions just in case",
   "id": "eb46fb307a139637"
  },
  {
   "cell_type": "code",
   "source": [
    "def populate_dataframe_with_ip_classification(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    ips_classified = json_file_to_dict(ANYCAST_IP_CLASSIFICATION_FILEPATH)\n",
    "\n",
    "    for ip_classified in ips_classified.keys():\n",
    "        dataframe.loc[dataframe[\"ip_dest\"] == ip_classified, \"ip_anycast\"] = ips_classified[ip_classified]\n",
    "    \n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:01.035225Z",
     "start_time": "2024-05-09T10:06:01.019716Z"
    }
   },
   "id": "1c22e353dec78f8b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate a file with all the routes got as the result of the experiment execution"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "829bbc8293d73e11"
  },
  {
   "cell_type": "code",
   "source": [
    "# Auxiliary functions\n",
    "def get_probe_location(probe_id: int, origin_list: []) -> (float, float):\n",
    "    for origin in origin_list:\n",
    "        if probe_id == origin[\"probe_id\"]:\n",
    "            location = from_geojson(origin[\"location\"])\n",
    "            return location.y, location.x\n",
    "        else:\n",
    "            continue\n",
    "    return 0, 0\n",
    "\n",
    "def get_result_country_route(hunter_result: dict) -> dict:\n",
    "    probe_id = hunter_result[\"origin_id\"]\n",
    "    result_country = hunter_result[\"location_result\"][\"country\"]\n",
    "    probe_country = hunter_result[\"origin_country_code\"]\n",
    "\n",
    "    return {\n",
    "        \"origin_id\": probe_id,\n",
    "        \"origin_country\": probe_country,\n",
    "        \"result_country\": result_country\n",
    "    }\n",
    "\n",
    "def get_country_capital_coords(country_code: str) -> (float, float):\n",
    "    countries = {\n",
    "        \"DE\": (52.52437, 13.41053),\n",
    "        \"BE\": (50.85045, 4.34878),\n",
    "        \"HR\": (45.81444, 15.97798),\n",
    "        \"DK\": (55.67594, 12.56553),\n",
    "        \"ES\": (40.4165, -3.70256),\n",
    "        \"FR\": (48.85341, 2.3488),\n",
    "        \"IE\": (53.33306, -6.24889),\n",
    "        \"LV\": (56.946, 24.10589),\n",
    "        \"LU\": (49.61167, 6.13),\n",
    "        \"NL\": (52.37403, 4.88969),\n",
    "        \"BG\": (42.69751, 23.32415),\n",
    "        \"SK\": (48.14816, 17.10674),\n",
    "        \"SI\": (46.05108, 14.50513),\n",
    "        \"EE\": (59.43696, 24.75353),\n",
    "        \"GR\": (37.98376, 23.72784),\n",
    "        \"MT\": (35.89968, 14.5148),\n",
    "        \"PL\": (52.22977, 21.01178),\n",
    "        \"CZ\": (50.08804, 14.42076),\n",
    "        \"AT\": (48.20849, 16.37208),\n",
    "        \"CY\": (35.17531, 33.3642),\n",
    "        \"FI\": (60.16952, 24.93545),\n",
    "        \"HU\": (47.49835, 19.04045),\n",
    "        \"IT\": (41.89193, 12.51133),\n",
    "        \"LT\": (54.68916, 25.2798),\n",
    "        \"PT\": (38.71667, -9.13333),\n",
    "        \"RO\": (44.43225, 26.10626),\n",
    "        \"IS\": (64.13548, -21.89541),\n",
    "        \"LI\": (47.166, 9.555373),\n",
    "        \"NO\": (59.91273, 10.74609),\n",
    "        \"SE\": (59.32938, 18.06871)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        return countries[country_code]\n",
    "    except: \n",
    "        return 0,0\n",
    "\n",
    "def get_traceroute_routes(traceroute_measurement: dict) -> dict:\n",
    "    traceroute_routes = {}\n",
    "    for traceroute in traceroute_measurement:\n",
    "        probe_id = traceroute[\"prb_id\"]\n",
    "        traceroute_routes[probe_id] = []\n",
    "\n",
    "        traceroute_result = traceroute[\"result\"]\n",
    "        for hop in traceroute_result:\n",
    "            try:\n",
    "                hop_directions = list(set(\n",
    "                    [\n",
    "                        direction[\"from\"]\n",
    "                        for direction in hop[\"result\"]\n",
    "                        if \"from\" in direction.keys()\n",
    "                    ]\n",
    "                ))\n",
    "            except:\n",
    "                hop_directions = []\n",
    "            traceroute_routes[probe_id].append(hop_directions)\n",
    "\n",
    "    return traceroute_routes\n",
    "\n",
    "# Data generation function\n",
    "def generate_routes_results_raw():\n",
    "    routes_raw_df = pd.DataFrame(\n",
    "        columns=[\n",
    "            \"target\", \"probe_id\", \"ips_previous_to_target\", \"route\",\n",
    "            \"origin_country\", \"origin_latitude\", \"origin_longitude\", \n",
    "            \"capital_origin_latitude\", \"capital_origin_longitude\", \n",
    "            \"result_country\", \"result_latitude\", \"result_longitude\",\n",
    "            \"result_filename\", \"outside_EEE\"\n",
    "        ]\n",
    "    )\n",
    "    for result_filename in get_list_files_in_path(EXPERIMENT_RESULTS_FOLDER):\n",
    "        print(result_filename)\n",
    "        result = json_file_to_dict(f\"{EXPERIMENT_RESULTS_FOLDER}/{result_filename}\")\n",
    "        target = result[\"target\"]\n",
    "        origin_list = result[\"measurements\"][\"origin\"]\n",
    "        if \"traceroute\" in result[\"measurements\"][\"ripe_measurement_results\"].keys():\n",
    "            routes_traceroute_by_probe_id = get_traceroute_routes(result[\"measurements\"][\"ripe_measurement_results\"][\"traceroute\"])\n",
    "        else:\n",
    "            routes_traceroute_by_probe_id = []\n",
    "        for hunter_result in result[\"hunter_results\"]:\n",
    "            route = get_result_country_route(hunter_result)\n",
    "            probe_id = hunter_result[\"origin_id\"]\n",
    "            origin_country = route[\"origin_country\"]\n",
    "            origin_latitude, origin_longitude = get_probe_location(probe_id, origin_list)\n",
    "            capital_origin_latitude, capital_origin_longitude = get_country_capital_coords(origin_country)\n",
    "            \n",
    "            result_country = route[\"result_country\"]\n",
    "            if len(hunter_result[\"location_result\"][\"airports_intersection\"]) == 1:\n",
    "                result_location = from_geojson(hunter_result[\"location_result\"][\"airports_intersection\"][0][\"location\"])\n",
    "                result_latitude = result_location.y\n",
    "                result_longitude = result_location.x\n",
    "            else:\n",
    "                result_latitude = 0\n",
    "                result_longitude = 0\n",
    "                \n",
    "            outside_eee = (result_country not in EEE_countries_set) and (result_country != \"Indeterminate\")\n",
    "            \n",
    "            if result_country == \"Indeterminate\":\n",
    "                ips_previous_to_target = [\"Indeterminate\"]\n",
    "            else:\n",
    "                ips_previous_to_target = [\n",
    "                    ip[\"ip\"]\n",
    "                    for ip in hunter_result[\"ips_previous_to_target\"]\n",
    "                ]\n",
    "            \n",
    "            try:\n",
    "                probe_route = routes_traceroute_by_probe_id[probe_id]\n",
    "            except:\n",
    "                probe_route = []\n",
    "                \n",
    "            routes_raw_df = pd.concat(\n",
    "                [pd.DataFrame([[\n",
    "                    target, probe_id, str(ips_previous_to_target), str(probe_route),\n",
    "                    origin_country, origin_latitude, origin_longitude, \n",
    "                    capital_origin_latitude, capital_origin_longitude,\n",
    "                    result_country, result_latitude, result_longitude,\n",
    "                    result_filename, outside_eee\n",
    "                ]], columns=routes_raw_df.columns), routes_raw_df], \n",
    "                ignore_index=True\n",
    "            )\n",
    "            \n",
    "    # Sort and save\n",
    "    routes_raw_df.sort_values(by=[\"target\", \"origin_country\", \"result_country\"], inplace=True)\n",
    "    routes_raw_df.to_csv(ROUTES_RESULTS_FILENAME, sep=\",\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:01.047511Z",
     "start_time": "2024-05-09T10:06:01.035975Z"
    }
   },
   "id": "3a4a5ff135ebc9cc",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Once we have collected all the routes, we proceed to clean and filtered the results",
   "id": "c31cc91b4e58791e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:01.063554Z",
     "start_time": "2024-05-09T10:06:01.048349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_probe_ip_from_route(route_str: str) -> str:\n",
    "    route = literal_eval(route_str)\n",
    "    if len(route) != 0 and len(route[0]) != 0:\n",
    "        return route[0][0]\n",
    "    else:\n",
    "        return \"0.0.0.0\"\n",
    "\n",
    "def get_ip_details_via_cache(ip_address: str) -> dict:\n",
    "    url = f\"{IP_URL}/{ip_address}\"\n",
    "    details = json.loads(requests.get(url=url).json()[\"details\"])\n",
    "    return details\n",
    "\n",
    "def get_ip_country_via_cache(ip_address: str) -> str:\n",
    "    ip_details = get_ip_details_via_cache(ip_address)\n",
    "    if \"bogon\" in ip_details.keys():\n",
    "        return \"bogon\"\n",
    "    else:\n",
    "        return ip_details[\"country\"]\n",
    "\n",
    "def add_probe_id_ip_country_location(routes_results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if \"probe_ip\" in routes_results_df.columns:\n",
    "        routes_results_df[\"probe_ip\"] = \"0.0.0.0\"\n",
    "    else:\n",
    "        routes_results_df.insert(2, \"probe_ip\", \"0.0.0.0\")\n",
    "\n",
    "    if \"probe_country_with_ip\" in routes_results_df.columns:\n",
    "        routes_results_df[\"probe_country_with_ip\"] = \"bogon\"\n",
    "    else:\n",
    "        routes_results_df.insert(3, \"probe_country_with_ip\", \"bogon\")\n",
    "    \n",
    "    # Get probes ips from traceroute\n",
    "    routes_results_df[\"probe_ip\"] = routes_results_df[\"route\"].apply(\n",
    "        lambda route: get_probe_ip_from_route(route)\n",
    "    )\n",
    "    \n",
    "    for probe_ip in routes_results_df[\"probe_ip\"].unique():\n",
    "        if probe_ip != \"0.0.0.0\" and (not ipaddress.ip_address(probe_ip).is_private):\n",
    "            routes_results_df.loc[\n",
    "                routes_results_df[\"probe_ip\"] == probe_ip, \n",
    "                \"probe_country_with_ip\"\n",
    "            ] = get_ip_country_via_cache(probe_ip)\n",
    "    \n",
    "    return routes_results_df\n",
    "\n",
    "def mark_suspicious_routes_results(routes_results_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    routes_results_df[\"suspicious\"] = False\n",
    "\n",
    "    # Count the probes that made a specific route\n",
    "    routes_results_probe_count_df = routes_results_df[\n",
    "        [\"target\", \"result_country\", \"probe_id\"]\n",
    "    ].groupby(\n",
    "        [\"target\", \"result_country\"]\n",
    "    )[\"probe_id\"].count().reset_index(\n",
    "        [\"target\", \"result_country\"]\n",
    "    ).rename(\n",
    "        columns={\"probe_id\":\"probes_count\"}\n",
    "    )\n",
    "    \n",
    "    if \"probes_count\" in routes_results_df.columns:\n",
    "        routes_results_df.drop(\"probes_count\", axis=1, inplace=True)\n",
    "    \n",
    "    routes_results_df = pd.merge(\n",
    "        routes_results_df,\n",
    "        routes_results_probe_count_df,\n",
    "        on=[\"target\", \"result_country\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    \n",
    "    # Validation criteria\n",
    "    routes_results_df.loc[\n",
    "        (routes_results_df[\"probes_count\"] < 2) &\n",
    "        (routes_results_df[\"result_country\"] != \"Indeterminate\"),\n",
    "        \"suspicious\"\n",
    "    ] = True\n",
    "\n",
    "    routes_results_df.loc[\n",
    "        (routes_results_df[\"probe_country_with_ip\"] != routes_results_df[\"origin_country\"]) &\n",
    "        (routes_results_df[\"probe_country_with_ip\"] != \"bogon\"),\n",
    "        \"suspicious\"\n",
    "    ] = True\n",
    "    \n",
    "    return routes_results_df\n",
    "    \n",
    "def clean_routes_results():\n",
    "    routes_results_raw_df = pd.read_csv(ROUTES_RESULTS_FILENAME, sep=\",\")\n",
    "    routes_results_raw_df = add_probe_id_ip_country_location(routes_results_raw_df)\n",
    "    routes_results_raw_df = mark_suspicious_routes_results(routes_results_raw_df)\n",
    "    \n",
    "    routes_results_raw_df.to_csv(ROUTES_RESULTS_FILENAME, sep=\",\", index=False)\n",
    "    routes_results_raw_df.loc[\n",
    "        routes_results_raw_df[\"suspicious\"] != True\n",
    "    ].to_csv(ROUTES_RESULTS_NON_SUSPICIOUS_FILENAME, sep=\",\", index=False)\n",
    "    routes_results_raw_df.loc[\n",
    "        routes_results_raw_df[\"suspicious\"] == True\n",
    "    ].to_csv(ROUTES_RESULTS_SUSPICIOUS_FILENAME, sep=\",\", index=False)\n",
    "    "
   ],
   "id": "6d69bde83fa03041",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregate and count routes repetitions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2905481c5a38b1ac"
  },
  {
   "cell_type": "code",
   "source": [
    "def generate_routes_frequency_aggregation(routes_results_file: str, routes_frequency_file: str):\n",
    "    # Aggregate routes counting the repetitions\n",
    "    routes_frequency_df = pd.read_csv(routes_results_file, sep=\",\")\n",
    "\n",
    "    routes_frequency_df = routes_frequency_df.value_counts(\n",
    "        subset=['target', 'origin_country', 'result_country']\n",
    "    ).rename_axis(\n",
    "        ['target', 'origin_country', 'result_country']\n",
    "    ).reset_index(\n",
    "        name=\"count\"\n",
    "    )\n",
    "    \n",
    "    routes_frequency_df[\"outside_EEE\"] = False\n",
    "    routes_frequency_df.loc[\n",
    "        (routes_frequency_df[\"result_country\"] != \"Indeterminate\") &\n",
    "        (~routes_frequency_df[\"result_country\"].isin(EEE_countries_set)),\n",
    "        [\"outside_EEE\"]\n",
    "    ] = True\n",
    "    routes_frequency_df.to_csv(routes_frequency_file, sep=\",\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:01.085765Z",
     "start_time": "2024-05-09T10:06:01.064292Z"
    }
   },
   "id": "1ef13530479b1cbb",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Execute the enrichment of data and generation",
   "id": "ab0ffdadb9019c0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:20.313892Z",
     "start_time": "2024-05-09T10:06:01.087395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Because is a long process and is only necessary to run once I include the condition\n",
    "if GENERATE_ROUTES_RAW:\n",
    "    # Generate the results raw\n",
    "    generate_routes_results_raw()\n",
    "if GENERATE_ROUTES_ADDONS:\n",
    "    # Make the cleaning and enrichment of the data\n",
    "    clean_routes_results()\n",
    "    # Generate the frequency results\n",
    "    for file_tuple in [(ROUTES_RESULTS_FILENAME, ROUTES_FREQUENCY_FILENAME),\n",
    "                       (ROUTES_RESULTS_NON_SUSPICIOUS_FILENAME, ROUTES_FREQUENCY_NON_SUSPICIOUS_FILENAME),\n",
    "                       (ROUTES_RESULTS_SUSPICIOUS_FILENAME, ROUTES_FREQUENCY_SUSPICIOUS_FILENAME),]:\n",
    "        generate_routes_frequency_aggregation(file_tuple[0], file_tuple[1])"
   ],
   "id": "5c2b8a81fc6a215b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Populate traffic logs\n",
    "\n",
    "The next phase is to populate and filter the traffic logs dataset in order to be able to extract the conclusions from one point with the complete info."
   ],
   "id": "984e8e856d1f483c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Introduce routes outside EEE and its count in the complete dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b51ebb6a53d3489d"
  },
  {
   "cell_type": "code",
   "source": [
    "# Dataset population function\n",
    "def populate_dataset_with_routes_results(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    routes_valid_df = pd.read_csv(ROUTES_FREQUENCY_NON_SUSPICIOUS_FILENAME, sep=\",\")\n",
    "    routes_valid_df = routes_valid_df.loc[\n",
    "        (routes_valid_df[\"outside_EEE\"] == True)\n",
    "    ]\n",
    "\n",
    "    # Charge default routes in the dataset to populate\n",
    "    dataframe[\"origins_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"destinations_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"frequency_transfers_outside_EEE\"] = \"[]\"\n",
    "    dataframe[\"outside_EEE\"] = False\n",
    "    \n",
    "    # For every IP get the list of origins, destinations and frequency and save it\n",
    "    for ip in routes_valid_df[\"target\"].unique().tolist():\n",
    "        ip_routes = routes_valid_df.loc[routes_valid_df[\"target\"] == ip]\n",
    "        origins_transfers_outside_eee = ip_routes[\"origin_country\"].values.tolist()\n",
    "        destinations_transfers_outside_eee = ip_routes[\"result_country\"].values.tolist()\n",
    "        frequency_transfers_outside_eee = ip_routes[\"count\"].values.tolist()\n",
    "\n",
    "        dataframe.loc[\n",
    "            (dataframe[\"ip_dest\"] == ip), \n",
    "            [\"origins_transfers_outside_EEE\", \n",
    "             \"destinations_transfers_outside_EEE\", \n",
    "             \"frequency_transfers_outside_EEE\",\n",
    "             \"outside_EEE\"]\n",
    "        ] = [str(origins_transfers_outside_eee),\n",
    "             str(destinations_transfers_outside_eee),\n",
    "             str(frequency_transfers_outside_eee),\n",
    "             True]\n",
    "    \n",
    "    return dataframe\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:20.317720Z",
     "start_time": "2024-05-09T10:06:20.314656Z"
    }
   },
   "id": "c5fdd5566a17a165",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with metadata info"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f4e872e6e4f5f347"
  },
  {
   "cell_type": "code",
   "source": [
    "def populate_dataset_with_apks_metadata(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    apk_metadata_df = pd.read_csv(APKS_METADATA_FILEPATH, sep=\",\")\n",
    "    \n",
    "    return dataframe.merge(\n",
    "        apk_metadata_df,\n",
    "        on=[\"apk\", \"version\"],\n",
    "        how=\"left\"\n",
    "    )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:20.333912Z",
     "start_time": "2024-05-09T10:06:20.318742Z"
    }
   },
   "id": "6b1c5cf65806854e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with the info extrated from every policy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cce1d5fd8c0c621b"
  },
  {
   "cell_type": "code",
   "source": [
    "def populate_dataset_with_policy_extracted_info(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    it_annotation_results_df = pd.read_csv(IT_ANNOTATION_FILEPATH, sep=\",\")\n",
    "    \n",
    "    it_annotation_results_df.drop_duplicates([\"apk\", \"countries\"], inplace=True)\n",
    "    it_annotation_results_df.rename(\n",
    "        columns={\n",
    "            \"transfer\": \"it_mentioned_by_policy\",\n",
    "            \"adequacy_decision\": \"adequacy_decision_by_policy\",\n",
    "            \"countries\": \"countries_mentioned_by_policy\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )\n",
    "    \n",
    "    dataframe = pd.merge(\n",
    "        dataframe,\n",
    "        it_annotation_results_df[[\n",
    "            \"apk\", \"version\", \n",
    "            \"it_mentioned_by_policy\", \"adequacy_decision_by_policy\", \"countries_mentioned_by_policy\"\n",
    "        ]], \n",
    "        on=[\"apk\", \"version\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    dataframe.fillna(\n",
    "        value={\n",
    "            \"it_mentioned_by_policy\": False,\n",
    "            \"adequacy_decision_by_policy\": False,\n",
    "            \"countries_mentioned_by_policy\": \"[]\"\n",
    "        },\n",
    "        inplace=True\n",
    "    )    \n",
    "    return dataframe\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:20.345486Z",
     "start_time": "2024-05-09T10:06:20.334650Z"
    }
   },
   "id": "4b79f08eb4c84797",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "Populate the datasets with the info about the libraries which carried out the communication "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da2d74b9a83b5b19"
  },
  {
   "cell_type": "code",
   "source": [
    "def populate_dataset_with_libraries_data(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    tpls_results_df = pd.read_csv(TPLS_RESULTS_FILEPATH, sep=\",\")\n",
    "    tpls_results_df.fillna(\n",
    "        {\n",
    "            \"TP-performed\": False,\n",
    "            \"TP-library\": \"None\",\n",
    "            \"FP-intended\": False,\n",
    "        }, inplace=True\n",
    "    )\n",
    "    \n",
    "    dataframe.drop(\"stackTrace\", axis=1, inplace=True)\n",
    "    \n",
    "    dataframe = pd.merge(\n",
    "        dataframe,\n",
    "        tpls_results_df[[\n",
    "            \"apk\", \"stackTrace\", \"version\", \"port_source\", \"host\", \"port_dest\", \"ip_dest\",\n",
    "            \"TP-performed\", \"TP-library\", \"FP-intended\"\n",
    "        ]],\n",
    "        on=[\"apk\", \"version\", \"port_source\", \"host\", \"port_dest\", \"ip_dest\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    return dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:20.361343Z",
     "start_time": "2024-05-09T10:06:20.346463Z"
    }
   },
   "id": "f4c048778787baae",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "Check GDPR compliance in terms of international transfers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a790c34e9a0bfc98"
  },
  {
   "cell_type": "code",
   "source": [
    "def check_apk_it_gdpr_compliance(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    dataframe[\"apk_it_gdpr_compliance\"] = True\n",
    "    \n",
    "    dataframe[\"apk_it_gdpr_compliance\"] = dataframe.apply(\n",
    "        lambda row_to_check: \n",
    "        set(literal_eval(row_to_check[\"destinations_transfers_outside_EEE\"])).issubset(\n",
    "            set(literal_eval(row_to_check[\"countries_mentioned_by_policy\"]))\n",
    "        ),\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return dataframe\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:20.372194Z",
     "start_time": "2024-05-09T10:06:20.362211Z"
    }
   },
   "id": "918ecd5bac3f9b42",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "Aggregation of apk and destination IP by domain or host"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88534750de51daa3"
  },
  {
   "cell_type": "code",
   "source": [
    "def aggregate_by_domain(dataframe: pd.DataFrame, filepath: str):\n",
    "    group_df = dataframe[[\"host\", \"ip_dest\", \"apk\"]]\n",
    "    group_df = group_df.groupby([\"host\", \"ip_dest\", \"apk\"]).size().reset_index(name=\"traffic_logs\")\n",
    "\n",
    "    group_df.sort_values(by=[\"host\", \"apk\", \"ip_dest\"], inplace=True)\n",
    "    \n",
    "    group_df.to_csv(filepath, sep=\",\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:20.387571Z",
     "start_time": "2024-05-09T10:06:20.373353Z"
    }
   },
   "id": "64f7bf6493d860f6",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "Make the analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f7d4fdd4cf15c54"
  },
  {
   "cell_type": "code",
   "source": [
    "# Charge the dataframes to be used\n",
    "traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_FILEPATH, sep=\",\")\n",
    "anycast_pii_traffic_logs_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_FILEPATH, sep=\",\")\n",
    "datasets = [traffic_logs_ip_classified_analysis_df, anycast_pii_traffic_logs_df]\n",
    "analysis_filepaths = [TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH]\n",
    "aggregation_filepaths = [TRAFFIC_LOGS_IP_CLASSIFIED_HOST_AGGREGATION_FILEPATH, ANYCAST_PII_HOST_AGGREGATION_FILEPATH]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:06:21.105412Z",
     "start_time": "2024-05-09T10:06:20.388646Z"
    }
   },
   "id": "ca54aaa1dc002700",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Populate datasets\n",
    "if ANALYZE_DATA:\n",
    "    for index in range(0, len(datasets)):\n",
    "        dataset_to_improve = datasets[index]\n",
    "        \n",
    "        # Populate with metadata\n",
    "        print(\"Populate with metadata\")\n",
    "        dataset_to_improve = populate_dataset_with_apks_metadata(dataset_to_improve)\n",
    "        # Populate with the privacy policy extracted data\n",
    "        print(\"Populate with the privacy policy extracted data\")\n",
    "        dataset_to_improve = populate_dataset_with_policy_extracted_info(dataset_to_improve)\n",
    "        # Populate with routes\n",
    "        print(\"Populate with routes\")\n",
    "        dataset_to_improve = populate_dataset_with_routes_results(dataset_to_improve)\n",
    "        # Populate with libraries data\n",
    "        print(\"Populate with the libraries data\")\n",
    "        dataset_to_improve = populate_dataset_with_libraries_data(dataset_to_improve)\n",
    "    \n",
    "        # Check conditions\n",
    "        print(\"Checking IT declarations accomplishment\")\n",
    "        dataset_to_improve = check_apk_it_gdpr_compliance(dataset_to_improve)\n",
    "    \n",
    "        print(\"Setting types and NaN\")\n",
    "        dataset_to_improve.fillna(\n",
    "            {\n",
    "                \"loadsJNI\": False,\n",
    "                \"stackTrace\": \"None\",\n",
    "                \"remote_host\": \"None\",\n",
    "                \"tls\": False,\n",
    "                \"https\": False,\n",
    "                \"error\": \"None\",\n",
    "                \"TP-performed\": False,\n",
    "                \"TP-library\": \"None\",\n",
    "                \"FP-intended\": False,\n",
    "            }, inplace=True\n",
    "        )\n",
    "        \n",
    "        print(\"Saving data\")\n",
    "        dataset_to_improve.to_csv(analysis_filepaths[index], sep=\",\", index=False)\n",
    "        \n",
    "        # Generate the aggregations for better understanding\n",
    "        # aggregate_by_domain(dataframe=dataset_to_improve, filepath=aggregation_filepaths[index])\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:24.692168Z",
     "start_time": "2024-05-09T10:06:21.106100Z"
    }
   },
   "id": "47809ecc512817c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate with metadata\n",
      "Populate with the privacy policy extracted data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9083/2212109401.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataframe.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate with routes\n",
      "Populate with the libraries data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9083/1016865771.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tpls_results_df.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking IT declarations accomplishment\n",
      "Setting types and NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9083/1958308088.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset_to_improve.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving data\n",
      "Populate with metadata\n",
      "Populate with the privacy policy extracted data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9083/2212109401.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataframe.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populate with routes\n",
      "Populate with the libraries data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9083/1016865771.py:3: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  tpls_results_df.fillna(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking IT declarations accomplishment\n",
      "Setting types and NaN\n",
      "Saving data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9083/1958308088.py:24: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset_to_improve.fillna(\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Analysis questions\n",
    "\n",
    "Answers to the questions needed for the article\n",
    "\n",
    "Acronyms:\n",
    "- PII = Personal Identificable Information"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bd3273fca7aeeaa"
  },
  {
   "cell_type": "code",
   "source": [
    "# Data load\n",
    "traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, sep=\",\")\n",
    "anycast_pii_traffic_logs_analysis_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH, sep=\",\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:50.042223Z",
     "start_time": "2024-05-09T10:08:24.692883Z"
    }
   },
   "id": "4312ee087eaabf53",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9083/3233838539.py:2: DtypeWarning: Columns (8,23,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  traffic_logs_ip_classified_analysis_df = pd.read_csv(TRAFFIC_LOGS_IP_CLASSIFIED_ANALYSIS_FILEPATH, sep=\",\")\n",
      "/tmp/ipykernel_9083/3233838539.py:3: DtypeWarning: Columns (37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  anycast_pii_traffic_logs_analysis_df = pd.read_csv(ANYCAST_PII_TRAFFIC_LOGS_ANALYSIS_FILEPATH, sep=\",\")\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "source": [
    "Traffic numbers"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9d12092a81d77b8"
  },
  {
   "cell_type": "code",
   "source": [
    "all_connections = len(traffic_logs_ip_classified_analysis_df.index)\n",
    "print(f\"Number of connections intercepted: {all_connections}\")\n",
    "\n",
    "anycast_connections = len(anycast_pii_traffic_logs_analysis_df.index)\n",
    "print(f\"Number of anycast connections intercepted: {anycast_connections}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:50.045977Z",
     "start_time": "2024-05-09T10:08:50.043305Z"
    }
   },
   "id": "1c718eb434f411c7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connections intercepted: 4278823\n",
      "Number of anycast connections intercepted: 195786\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "source": [
    "**IPs analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88555225610e9127"
  },
  {
   "cell_type": "code",
   "source": [
    "ips_total = traffic_logs_ip_classified_analysis_df[\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs in traffic logs: {len(ips_total)}\")\n",
    "\n",
    "ips_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs with PII: {len(ips_total_pii)}\")\n",
    "\n",
    "ips_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs anycast: {len(ips_anycast)}\")\n",
    "\n",
    "ips_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs anycast with PII: {len(ips_anycast_pii)}\")\n",
    "\n",
    "ips_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna()) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"outside_EEE\"] == True)\n",
    "    ][\"ip_dest\"].unique().tolist()\n",
    "print(f\"Number of IPs anycast with PII that make IT: {len(ips_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:15:32.630441Z",
     "start_time": "2024-05-09T10:15:31.056439Z"
    }
   },
   "id": "a95eaa1142c4f4b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of IPs in traffic logs: 5647\n",
      "Number of IPs with PII: 1807\n",
      "Number of IPs anycast: 991\n",
      "Number of IPs anycast with PII: 200\n",
      "Number of IPs anycast with PII that make IT: 195\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Check the case of IPs with only one destination country detected",
   "id": "1a6e0cb2992c65f6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:25:44.592974Z",
     "start_time": "2024-05-09T10:25:44.577488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "routes_frequency_non_suspicious_df = pd.read_csv(ROUTES_FREQUENCY_NON_SUSPICIOUS_FILENAME, sep=\",\")\n",
    "ip_destinations_count_df = routes_frequency_non_suspicious_df.loc[\n",
    "        routes_frequency_non_suspicious_df[\"result_country\"] != \"Indeterminate\"\n",
    "    ].groupby([\"target\"], as_index=False)[\"result_country\"].nunique().rename(columns={\"result_country\": \"result_countries_count\"})\n",
    "\n",
    "ip_destinations_count_df.sort_values(by=\"result_countries_count\", ascending=True, inplace=True)\n",
    "\n",
    "ip_destinations_count_df"
   ],
   "id": "9becb4b064ec1f05",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             target  result_countries_count\n",
       "62    13.107.246.43                       1\n",
       "136  204.79.197.200                       1\n",
       "61    13.107.21.200                       2\n",
       "76    170.33.12.222                       4\n",
       "120  185.151.204.40                       4\n",
       "..              ...                     ...\n",
       "25   104.19.255.161                      30\n",
       "6       104.17.73.8                      30\n",
       "3    104.17.209.240                      30\n",
       "14    104.18.39.116                      30\n",
       "1    104.17.155.236                      31\n",
       "\n",
       "[218 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>result_countries_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>13.107.246.43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>204.79.197.200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>13.107.21.200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>170.33.12.222</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>185.151.204.40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>104.19.255.161</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104.17.73.8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.17.209.240</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>104.18.39.116</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.17.155.236</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:26:08.102046Z",
     "start_time": "2024-05-09T10:26:08.098410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ip_one_destination_country_list = ip_destinations_count_df.loc[\n",
    "    ip_destinations_count_df[\"result_countries_count\"] <= 1\n",
    "    ][\"target\"].unique().tolist()\n",
    "\n",
    "ip_one_destination_country_list"
   ],
   "id": "6ec34720930ea78a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.107.246.43', '204.79.197.200']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Make the last analysis but only for the IPs with at least one time a specific destination country",
   "id": "18caa72bd7b049e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T11:31:04.473851Z",
     "start_time": "2024-05-09T11:31:04.463543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result_country_to_filter = \"US\"\n",
    "\n",
    "ip_destinations_count_in_country_filter_df = routes_frequency_non_suspicious_df.loc[\n",
    "    (routes_frequency_non_suspicious_df[\"result_country\"] != \"Indeterminate\") &\n",
    "    (routes_frequency_non_suspicious_df[\"target\"].isin(\n",
    "        routes_frequency_non_suspicious_df.loc[\n",
    "            (routes_frequency_non_suspicious_df[\"result_country\"] != \"Indeterminate\") &\n",
    "            (routes_frequency_non_suspicious_df[\"result_country\"] == result_country_to_filter)\n",
    "        ][\"target\"].unique()\n",
    "    ))\n",
    "].groupby([\"target\"], as_index=False)[\"result_country\"].nunique().rename(columns={\"result_country\": \"result_countries_count\"})\n",
    "\n",
    "ip_destinations_count_in_country_filter_df.sort_values(by=\"result_countries_count\", ascending=True, inplace=True)\n",
    "\n",
    "ip_destinations_count_in_country_filter_df"
   ],
   "id": "ce5494ffb677ddb7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            target  result_countries_count\n",
       "30  185.151.204.51                       4\n",
       "25  185.151.204.40                       4\n",
       "22  185.151.204.30                       5\n",
       "21  185.151.204.14                       5\n",
       "32   185.151.204.9                       5\n",
       "29  185.151.204.50                       5\n",
       "28  185.151.204.43                       5\n",
       "20  185.151.204.12                       5\n",
       "19  185.151.204.11                       5\n",
       "27  185.151.204.42                       5\n",
       "24  185.151.204.33                       6\n",
       "31  185.151.204.60                       6\n",
       "23  185.151.204.31                       6\n",
       "26  185.151.204.41                       7\n",
       "12   172.64.167.21                      11\n",
       "11   172.64.166.21                      11\n",
       "10   172.64.141.14                      12\n",
       "9    172.64.140.14                      13\n",
       "1    104.21.234.19                      15\n",
       "8   162.247.243.24                      19\n",
       "33   185.221.87.36                      19\n",
       "15  172.67.189.184                      22\n",
       "34    188.114.96.5                      22\n",
       "13   172.67.165.78                      22\n",
       "0     104.21.11.61                      22\n",
       "35    188.114.97.5                      23\n",
       "7    104.21.69.134                      23\n",
       "5    104.21.61.123                      23\n",
       "4    104.21.53.121                      23\n",
       "3    104.21.39.235                      23\n",
       "2    104.21.37.162                      23\n",
       "16  172.67.208.245                      24\n",
       "14   172.67.187.43                      24\n",
       "6     104.21.62.59                      24\n",
       "18  172.67.220.162                      24\n",
       "17  172.67.212.209                      24"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>result_countries_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>185.151.204.51</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>185.151.204.40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>185.151.204.30</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>185.151.204.14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>185.151.204.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>185.151.204.50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>185.151.204.43</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>185.151.204.12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>185.151.204.11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>185.151.204.42</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>185.151.204.33</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>185.151.204.60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>185.151.204.31</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>185.151.204.41</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>172.64.167.21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>172.64.166.21</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>172.64.141.14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>172.64.140.14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.21.234.19</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>162.247.243.24</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>185.221.87.36</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>172.67.189.184</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>188.114.96.5</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>172.67.165.78</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104.21.11.61</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>188.114.97.5</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>104.21.69.134</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>104.21.61.123</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.21.53.121</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.21.39.235</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.21.37.162</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>172.67.208.245</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>172.67.187.43</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>104.21.62.59</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>172.67.220.162</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>172.67.212.209</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "cell_type": "markdown",
   "source": [
    "**APKS analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a71b37155d0389f5"
  },
  {
   "cell_type": "code",
   "source": [
    "apks_total = traffic_logs_ip_classified_analysis_df[\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs in traffic logs: {len(apks_total)}\")\n",
    "\n",
    "apks_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs with PII: {len(apks_total_pii)}\")\n",
    "\n",
    "apks_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs using anycast: {len(apks_anycast)}\")\n",
    "\n",
    "apks_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs anycast with PII: {len(apks_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:52.789665Z",
     "start_time": "2024-05-09T10:08:51.389302Z"
    }
   },
   "id": "76c72f39cb6c7d85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of APKs in traffic logs: 5759\n",
      "Number of APKs with PII: 3478\n",
      "Number of APKs using anycast: 1669\n",
      "Number of APKs anycast with PII: 960\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Hosts Analysis**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c98ce9aa4f43b5d2"
  },
  {
   "cell_type": "code",
   "source": [
    "hosts_total = traffic_logs_ip_classified_analysis_df[\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts in traffic logs: {len(hosts_total)}\")\n",
    "\n",
    "hosts_total_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts with PII: {len(hosts_total_pii)}\")\n",
    "\n",
    "hosts_anycast = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]\n",
    "][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts using anycast: {len(hosts_anycast)}\")\n",
    "\n",
    "hosts_anycast_pii = traffic_logs_ip_classified_analysis_df.loc[\n",
    "    (traffic_logs_ip_classified_analysis_df[\"ip_anycast\"]) &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"] != \"No-PII\") &\n",
    "    (traffic_logs_ip_classified_analysis_df[\"PII\"].notna())\n",
    "    ][\"host\"].unique().tolist()\n",
    "print(f\"Number of hosts anycast with PII: {len(hosts_anycast_pii)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.097579Z",
     "start_time": "2024-05-09T10:08:52.790585Z"
    }
   },
   "id": "5a9bcccc70a378d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hosts in traffic logs: 4738\n",
      "Number of hosts with PII: 966\n",
      "Number of hosts using anycast: 995\n",
      "Number of hosts anycast with PII: 201\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Data Types**  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22eacec4072b9aef"
  },
  {
   "cell_type": "code",
   "source": [
    "pii_data_types_anycast = anycast_pii_traffic_logs_analysis_df[\"PII\"].unique().tolist()\n",
    "print(f\"Types of PII data treated by anycast IPs:\")\n",
    "print(pii_data_types_anycast)\n",
    "\n",
    "pii_data_types_anycast_pii_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"]\n",
    "][\"PII\"].unique().tolist()\n",
    "print(f\"Types of PII data treated by anycast IPs that make IT:\")\n",
    "print(pii_data_types_anycast_pii_it)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.141985Z",
     "start_time": "2024-05-09T10:08:54.098476Z"
    }
   },
   "id": "c27f5d9f8c7fe13b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types of PII data treated by anycast IPs:\n",
      "['Device_Model', 'Google_Ad_ID', 'Build_No', 'Kernel_version', 'Fingerprint', 'Router_Wifi_BSSID', 'Router_Wifi_BSSID_Close', 'Router_Wifi_MAC', 'Device_location', 'Device_location_coarse']\n",
      "Types of PII data treated by anycast IPs that make IT:\n",
      "['Device_Model', 'Google_Ad_ID', 'Build_No', 'Kernel_version', 'Fingerprint', 'Router_Wifi_BSSID', 'Router_Wifi_BSSID_Close', 'Router_Wifi_MAC', 'Device_location', 'Device_location_coarse']\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "source": [
    "**GDPR Compliance**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d554e1ce805ee86"
  },
  {
   "cell_type": "code",
   "source": [
    "apks_anycast_pii_declare_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"it_mentioned_by_policy\"]\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that declare IT in privacy policy: {len(apks_anycast_pii_declare_it)}\")\n",
    "\n",
    "apks_anycast_pii_not_compliance = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    anycast_pii_traffic_logs_analysis_df[\"apk_it_gdpr_compliance\"] == False\n",
    "][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that has not compliance: {len(apks_anycast_pii_not_compliance)}\")\n",
    "\n",
    "apks_anycast_pii_not_compliance_declare_it = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"it_mentioned_by_policy\"] == True) &\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"apk_it_gdpr_compliance\"] == False)\n",
    "    ][\"apk\"].unique().tolist()\n",
    "print(f\"Number of APKs that use anycast IPs and treat PII that has not compliance and declare IT in privacy policy: {len(apks_anycast_pii_not_compliance_declare_it)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.197232Z",
     "start_time": "2024-05-09T10:08:54.142874Z"
    }
   },
   "id": "39f65ca46cf5f6ec",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of APKs that use anycast IPs and treat PII that declare IT in privacy policy: 196\n",
      "Number of APKs that use anycast IPs and treat PII that has not compliance: 947\n",
      "Number of APKs that use anycast IPs and treat PII that has not compliance and declare IT in privacy policy: 189\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TLPs**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "772e34f4c4130bdc"
  },
  {
   "cell_type": "code",
   "source": [
    "anycast_pii_connections = len(anycast_pii_traffic_logs_analysis_df.index)\n",
    "print(f\"Number of connections Anycast+PII: {anycast_pii_connections}\")\n",
    "\n",
    "anycast_pii_it_connections = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True)\n",
    "    ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT: {anycast_pii_it_connections}\")\n",
    "\n",
    "anycast_pii_it_connections_by_app = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"FP-intended\"] == True)\n",
    "    ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT set up by APP: {anycast_pii_it_connections_by_app}\")\n",
    "\n",
    "anycast_pii_it_connections_by_tpl = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"TP-performed\"] == True)\n",
    "        ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT set up by TPL: {anycast_pii_it_connections_by_tpl}\")\n",
    "\n",
    "anycast_pii_it_connections_by_tpl_fp_intended = len(\n",
    "    anycast_pii_traffic_logs_analysis_df.loc[\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"TP-performed\"] == True) &\n",
    "        (anycast_pii_traffic_logs_analysis_df[\"FP-intended\"] == True)\n",
    "        ].index)\n",
    "print(f\"Number of connections Anycast+PII+IT set up by TPL but allowed from FP: {anycast_pii_it_connections_by_tpl_fp_intended}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.274086Z",
     "start_time": "2024-05-09T10:08:54.198256Z"
    }
   },
   "id": "6c757064eb2128f3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of connections Anycast+PII: 195786\n",
      "Number of connections Anycast+PII+IT: 195432\n",
      "Number of connections Anycast+PII+IT set up by APP: 166976\n",
      "Number of connections Anycast+PII+IT set up by TPL: 61974\n",
      "Number of connections Anycast+PII+IT set up by TPL but allowed from FP: 56014\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "source": [
    "tpls_anycast_pii_ip = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"TP-library\"] != \"None\") &\n",
    "    (~anycast_pii_traffic_logs_analysis_df[\"TP-library\"].isnull())\n",
    "][\"TP-library\"].unique().tolist()\n",
    "\n",
    "print(\"List of TPLs Anycast+PII+IT\")\n",
    "print(tpls_anycast_pii_ip)\n",
    "print(f\"Number of TPLs Anycast+PII+IT: {len(tpls_anycast_pii_ip)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.297022Z",
     "start_time": "2024-05-09T10:08:54.274973Z"
    }
   },
   "id": "e3373c4dbe6b8191",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of TPLs Anycast+PII+IT\n",
      "['com.google', 'com.unity3d', 'com.onesignal', 'com.mob', 'com.bugsnag', 'com.newrelic.agent.android', 'com.android.volley', 'com.adjust.sdk', 'io.bidmachine', 'com.appodeal.ads', 'com.applovin', 'com.mixpanel.android', 'com.google.android.gms', 'com.kochava', 'com.adcolony', 'com.chartboost', 'com.mopub.volley', 'io.sentry', 'com.urbanairship', 'com.emarsys', 'com.leanplum', 'com.fyber', 'io.grpc', 'com.dynatrace']\n",
      "Number of TPLs Anycast+PII+IT: 24\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [
    "print(\"Ranking TPLs\")\n",
    "anycast_pii_traffic_logs_analysis_df.groupby([\"TP-library\"],as_index=False).size().sort_values(by=[\"size\"], ascending=False, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.309627Z",
     "start_time": "2024-05-09T10:08:54.298459Z"
    }
   },
   "id": "7f19a0fac0af1e7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranking TPLs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                    TP-library   size\n",
       "0                  com.unity3d  35072\n",
       "1                io.bidmachine   9200\n",
       "2       com.google.android.gms   4998\n",
       "3               com.adjust.sdk   3470\n",
       "4             com.appodeal.ads   3127\n",
       "5                   com.google   1980\n",
       "6               com.chartboost   1068\n",
       "7                      com.mob    568\n",
       "8                 com.adcolony    430\n",
       "9                 com.applovin    405\n",
       "10          com.android.volley    322\n",
       "11                 com.kochava    278\n",
       "12               com.onesignal    233\n",
       "13            com.mopub.volley    201\n",
       "14  com.newrelic.agent.android    178\n",
       "15                 com.bugsnag    178\n",
       "16        com.mixpanel.android     85\n",
       "17               com.dynatrace     73\n",
       "18            com.urbanairship     38\n",
       "19                   io.sentry     32\n",
       "20                 com.emarsys     16\n",
       "21                   com.fyber     10\n",
       "22                     io.grpc      8\n",
       "23                com.leanplum      4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP-library</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com.unity3d</td>\n",
       "      <td>35072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>io.bidmachine</td>\n",
       "      <td>9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>com.google.android.gms</td>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>com.adjust.sdk</td>\n",
       "      <td>3470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>com.appodeal.ads</td>\n",
       "      <td>3127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>com.google</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>com.chartboost</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>com.mob</td>\n",
       "      <td>568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>com.adcolony</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>com.applovin</td>\n",
       "      <td>405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>com.android.volley</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>com.kochava</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>com.onesignal</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>com.mopub.volley</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>com.newrelic.agent.android</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>com.bugsnag</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>com.mixpanel.android</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>com.dynatrace</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>com.urbanairship</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>io.sentry</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>com.emarsys</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>com.fyber</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>io.grpc</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>com.leanplum</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "TPLs Privacy Policy declarations and analysis of complaince",
   "id": "5b3680a557c3aa5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.361317Z",
     "start_time": "2024-05-09T10:08:54.310517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tpls_policy_analysis_df = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"outside_EEE\"] == True) &\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"TP-library\"] != \"None\") &\n",
    "    (~anycast_pii_traffic_logs_analysis_df[\"TP-library\"].isnull())\n",
    "    ][\n",
    "    [\"TP-library\", \"FP-intended\", \"host\", \"destinations_transfers_outside_EEE\", \"PII\"]\n",
    "].value_counts(\n",
    "    subset=[\"TP-library\", \"FP-intended\", \"host\", \"destinations_transfers_outside_EEE\", \"PII\"]\n",
    ").reset_index(\n",
    ").sort_values(\n",
    "    by=[\"TP-library\", \"FP-intended\", \"host\"]\n",
    ").merge(\n",
    "    pd.read_csv(TPLS_MANUAL_POLICY_INFO, sep=\",\"),\n",
    "    on=\"TP-library\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "tpls_policy_analysis_df[\"destinations_transfers_outside_EEE\"] = (\n",
    "    tpls_policy_analysis_df[\"destinations_transfers_outside_EEE\"].apply(\n",
    "        lambda country_list: str(list(set(literal_eval(country_list)))),\n",
    "    ))\n",
    "\n",
    "tpls_policy_analysis_df[\"tpl_gdpr_compliance\"] = tpls_policy_analysis_df.apply(\n",
    "    lambda row: set(literal_eval(row[\"destinations_transfers_outside_EEE\"])).issubset(set(literal_eval(row[\"countries_mentioned\"]))),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "tpls_policy_analysis_df.loc[\n",
    "    tpls_policy_analysis_df[\"PII_responsible\"]\n",
    "].to_csv(TPLS_POLICY_ANALYSIS, sep=\",\", index=False)"
   ],
   "id": "4b269417726a94a2",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Partial Results"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9361948247880a97"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One result to analysis some important apk examples",
   "id": "acb6542aaf5dc19b"
  },
  {
   "cell_type": "code",
   "source": [
    "downloads = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"apk_it_gdpr_compliance\"] == False) &\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"android_numDownloads\"] == \"1B+\")\n",
    "][\"apk\"].unique().tolist()\n",
    "print(downloads)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.372900Z",
     "start_time": "2024-05-09T10:08:54.362720Z"
    }
   },
   "id": "107b82f139d28224",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['com.fingersoft.hillclimb']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:54.395328Z",
     "start_time": "2024-05-09T10:08:54.373637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "apk = anycast_pii_traffic_logs_analysis_df.loc[\n",
    "    (anycast_pii_traffic_logs_analysis_df[\"apk\"] == \"com.fingersoft.hillclimb\")\n",
    "]\n",
    "apk.to_csv(f\"{PARTIAL_RESULTS_DIR}/one_app_results_{ANALYSIS_MODE}.csv\", sep=\",\", index=False)"
   ],
   "id": "10304a09d8bcd574",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generation of the same results but separated by country",
   "id": "2062db1f0a84e44f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:55.163683Z",
     "start_time": "2024-05-09T10:08:54.396115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "routes_results = pd.read_csv(ROUTES_RESULTS_NON_SUSPICIOUS_FILENAME, sep=\",\")\n",
    "routes_frequencies = pd.read_csv(ROUTES_FREQUENCY_NON_SUSPICIOUS_FILENAME, sep=\",\")\n",
    "# for origin_country in [\"CZ\"]:\n",
    "for origin_country in routes_results[\"origin_country\"].unique():\n",
    "    routes_results.loc[\n",
    "        (routes_results[\"origin_country\"] == origin_country) &\n",
    "        (routes_results[\"outside_EEE\"] == True)\n",
    "    ].sort_values(\n",
    "        by=[\"result_country\"]\n",
    "    ).to_csv(f\"{PARTIAL_RESULTS_DIR}/{ANALYSIS_MODE}/routes_results_{ANALYSIS_MODE}_{origin_country}.csv\", sep=\",\", index=False)\n",
    "\n",
    "    routes_frequencies.loc[\n",
    "        (routes_frequencies[\"origin_country\"] == origin_country) &\n",
    "        (routes_frequencies[\"outside_EEE\"] == True)\n",
    "    ].sort_values(\n",
    "        by=[\"result_country\"]\n",
    "    ).to_csv(f\"{PARTIAL_RESULTS_DIR}/{ANALYSIS_MODE}/routes_frequency_{ANALYSIS_MODE}_{origin_country}.csv\", sep=\",\", index=False)"
   ],
   "id": "a20ab6057464413a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Show the suspicious results divided for IP",
   "id": "ff9306ff283392dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-09T10:08:56.709085Z",
     "start_time": "2024-05-09T10:08:55.164579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for ip in pd.read_csv(ROUTES_RESULTS_SUSPICIOUS_FILENAME)[\"target\"].unique():\n",
    "    routes_results.loc[\n",
    "        (routes_results[\"outside_EEE\"] == True) &\n",
    "        (routes_results[\"target\"] == ip)\n",
    "    ].to_csv(f\"{PARTIAL_RESULTS_DIR}/{ANALYSIS_MODE}/{ip}_results.csv\", sep=\",\", index=False)"
   ],
   "id": "75979c5ea40d05c7",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# END",
   "id": "9dc3410454746c8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
